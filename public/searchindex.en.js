var relearn_searchindex = [
  {
    "breadcrumb": "Chaslinux's Blog",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Chaslinux's Blog",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Gaming",
    "uri": "/categories/gaming/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Gaming",
    "uri": "/tags/gaming/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Hardware",
    "uri": "/categories/hardware/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Linux",
    "uri": "/categories/linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Linux",
    "uri": "/tags/linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Linux Mint",
    "uri": "/tags/linux-mint/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Posts",
    "uri": "/posts/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Refurbishing",
    "uri": "/tags/refurbishing/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Steam",
    "uri": "/tags/steam/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Debian package over flatpak, but get it from Steam Moving from Xubuntu to Linux Mint XFCE was not as seemless as I’d hoped it would be. The last time I gave Linux Mint serious consideration was over 13 years ago when the Computer Recycling Project at The Working Centre was looking for a replacement for Ubuntu 10.04 (the next version would include the Unity desktop which wouldn’t run on a lot of our laptops at the time).\nI remember thinking at the time that Xubuntu looked slicker, and had a better update program than Xubuntu. But Xubuntu seemed to run better on a wider range of hardware than Linux Mint, and there were some issues I can’t recall, that were show stoppers for us at the time.\nOne of the things I consider to be a show stopper is if Steam doesn’t work. I’m sad to say that Linux Mint 21.3 has Steam issues. These issues are resolvable, but since Linux Mint is often touted as a “new user-friendly” Linux distribution, I’d expect the issues to be solved in a major release like Virginia (21.3).\nWhat Steam Issues? While Linux Mint supports flatpak, there seem to be ample web sites that suggest that flatpaks pose security problems. Common advice seems to be use a Debian package first, and only use flatpak’s when:\nYou need a later version of a program The software isn’t in the distribution’s software repository I installed the Steam flatpak to see how it performed. On my desktop workstation it performed admirably. I had no problem installing Steam, and was able to play Path of Exile with decent performance (R7 2700X CPU and an RX5500 video card). While I never paid attention on Xubuntu to how many FPS I got (because it was smooth), I didn’t notice a difference with the flatpak on Mint.\nBut, I decided to follow the common advice and install Steam from the software repositories, only to discover there were missing libraries. This prompted me to uninstall, and pick up the Debian package directly from Steam/Valve.\nThe Valve Steam Debian package seemed to work fine initially. I installed Clicker Heroes, an IDLE RPG that needs to be installed via Proton. It worked without issue. But when I went to play Path of Exile, performance was noticeably bad – it felt like I was running on a system with low-end integrated graphics.\nA bit more digging and I discovered that the problem was likely due to the fact that Linux Mint 21.3 (Virginia) uses a fairly old kernel (5.15.0-112) out of the box, a kernel that doesn’t appear to properly support the RX5500.\nLinux Mint actually makes installing a new kernel fairly simple:\nOpen the Update Manager Click View \u003e Linux Kernels Click through the notification that warns about wireless and other potential issues installing a new kernel Pick the kernel you want and click install Reboot and pray This fixed my issue with Path of Exile performance on the Valve version of Steam.\nBut this method has 2 problems: First, it’s not really that newbie-friendly as it involves several steps. Second, it can’t be scripted easily.",
    "description": "Debian package over flatpak, but get it from Steam Moving from Xubuntu to Linux Mint XFCE was not as seemless as I’d hoped it would be. The last time I gave Linux Mint serious consideration was over 13 years ago when the Computer Recycling Project at The Working Centre was looking for a replacement for Ubuntu 10.04 (the next version would include the Unity desktop which wouldn’t run on a lot of our laptops at the time).",
    "tags": [
      "Gaming",
      "Linux Mint",
      "Linux",
      "Refurbishing",
      "Steam"
    ],
    "title": "Steam On Linux Mint 21.3 (Virginia)",
    "uri": "/posts/steam_on_linux_mint_21_3_virginia/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: 1080p",
    "uri": "/tags/1080p/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: 4k",
    "uri": "/tags/4k/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Blu-Ray",
    "uri": "/tags/blu-ray/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: DVD",
    "uri": "/tags/dvd/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Encoding",
    "uri": "/tags/encoding/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: FPS",
    "uri": "/tags/fps/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Handbrake",
    "uri": "/tags/handbrake/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Hardware",
    "uri": "/tags/hardware/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Hardware and Linux Distribution Differences This post covers a bunch of areas of media decoding and encoding that I’ve discovered over a number of years using Debian-based distributions like Xubuntu, and Linux Mint. Primarily I’ll cover some of the differences between Xubuntu and Linux Mint, how various hardware (CPUs and graphics cards) encode video, and some of the “gotchas” when it comes to different methods as they apply to Handbrake (software) and MakeMKV.\nFirst – straight up numbers I’m going to blather on about various topics so I thought I’d start by getting straight to the point with CPU vs GPU encoding. This is strictly using Handbrake under either Linux Mint, or Xubuntu. The version of Handbrake varies slightly on a couple of results, but most results are using Handbrake 1.7.2. There are 4 potential Handbrake “presets.” I’ve modified each of these “presets” to include all subtitles in the video. The same video and presets were copied to a key and used on each system. I wanted to test a large variety of old and slightly newer systems. I don’t have access to the latest hardware, so you won’t see any NVidia RTX 4090 cards, or 14th gen Intel systems, but I did manage to spend a bit of time with a 12th gen Intel system.\nFig. 1 - Video encoding results for various hardware\nThe presets are Fast 1080p 30 FPS H.264 which uses raw CPU encoding, Quicksync H.265 1080p which uses special “quicksync” instructions found on most Intel processors since the 2nd gen i-Series processors (note: not all Intel processors support this – see the top 7th gen Pentium G4560 which failed when we tried), NVENC H.265 1080p which is supported by most newer NVidia cards (and some pretty old ones), and VCN 1080p H.265 1080p encoding.\nThe original video was an encrypted DVD that was turned into a MKV along with all subtitles using MakeMKV.\nThe clear winner of the encoding battle was won by the NVidia Quadro P1000 4GB video card. The P1000 is remarkably a small, thin card that requires no power outside of the PCIe slot it fits in. It has 4 x mini-Display Port outputs for up to 4 monitors. The system it was running on is none other than the dual-monitor workstation I frequently use at The Working Centre’s Computer Recycling Project. The project has run Xubuntu Linux since a bit before 2010, only recently moving more towards Linux Mint. There are some advantages to using Xubuntu over Linux Mint that do not have to do with encoding numbers, but I’ll get to those further down. This winning result was using the Nvidia NVENC preset. I’ve run into issues with this preset which I’ll also explain further down. For now the important take-away is that this 2017 4GB graphics card will give you a better encoding result than a 2022 CPU with Quicksync enabled. There’s an asterisk here that I’ll explain after the next result.\nThe Intel Core i5-12400 CPU with the Quicksync preset enabled comes in second with a bit less than 100 FPS under the Quadro P1000. This might not seem like much, but if you’re encoding a lot of video, it could be significant. And this is where NVenc fell down for me. NVenc was fine for encoding 1 video at a time, but if I queued videos in Handbrake, like you would for something like a season of television shows, NVenc didn’t seem to activate. I’m not sure if this was a bug. I also cannot say if this was true for Quicksync as I only tried queuing videos on the Fast 1080p preset (it worked) and NVenc.\nThe third top result is also an interesting result. The Nvidia Quadro M4000 is an 8GB video card from 2015. What makes this result interesting is the fact that the card is an 8GB card, less memory than our top result 4GB card. This result suggests encoding isn’t so much about RAM as it is the improved technology of the newer 2017 card.\nWhat isn’t in these top 3 results, the 10 core 20 thread Intel XEON E2690 v2 CPU, nor the Ryzen 7 2700X 8 core 16 thread CPU. In fact both of these ranked lower than a 4th generation Intel Core i7-4770 with Quicksync. The E2690 V2 doesn’t support Quicksync, and the Ryzen 7 2700X just can’t keep up to quicksync. There is a result showing the Ryzen 7 2700X above the i7-4770, but this was the AMD RX 5500 graphics card with VCN enabled using the VCN preset. It also lagged behind our top performers.\nThe takeaway from these top encoders are: if you’re on an older system and looking for a cheap way to encode a few videos, buy a Quadro P1000 video card. The P1000 is easy on your computer’s resources (low powered card). Don’t look on Amazon for these cards as Amazon sellers have them on for $200+. Ebay is probably the best bet with these cards sometimes going for around $100CDN – it’s not super cheap, but compared to buying a complete 12th gen desktop it is.\nIf you’ve got money to burn I would argue a desktop with an Intel Core i5-12400 is the better choice despite the 100 FPS less as you always have the option to add a newer NVidia card for even better performance.\nGenerally speaking, the newer the technology, the better, but this is not always true, as this chart suggests. Even with quicksync enabled, our Tiny Form Factor Dell Optiplex 3050s with their 7th generation Intel Core i5-7500T CPUs could not beat the 4th generation i7-4770 without quicksync enabled … so what’s going on here? Quit simply the i5-7500T CPU is really designed for the embedded, low-power draw market. At a TDP of 35W the i5-7500T is a decent CPU, but it just cannot compete with the i7-4770 desktop processor which has a TDP of around 85W and higher base and max turbo frequencies. With quicksync enabled the i7-4770 (non-K) is more than 100 FPS better than the i5-7500T for video encoding. Does this make the i5-7500T a bad processor, not at all, it’s just not as good as the older i7 for this particular task.\nHandbrake – Xubuntu vs Linux Mint Using Handbrake under Xubuntu was a more pleasant experience than using it under Linux Mint. When queuing multiple files, Handbrake under Linux Mint returns you to a top-level directory. This means if you have videos stored under ~/Videos, you have to drill down to that directory, or whatever sub-directory under this that the episode is stored in. For example ~/Videos/Night_Court. Each time you add a file to a queue Handbrake returns you to a top level directory where you have to drill down to ~/Videos/Night_Court to get the second, then again for the third file, and so on. Handbrake under Xubuntu returns you to the directory the last queued file was in, so if you’re queuing multiple files you simply choose the next file and add it to the queue. This is not only time saving, but hand-stress saving.\nSummary Newer is not necessarily better, especially if you’re on a tight budget. If you have lots of cash, and plan on doing lots of video encoding then a modern Intel-based system with a modern NVidia GPU is probably going to be your best bet. While we didn’t have any Nvidia GPUs newer than the 2017 P1000 to test with, I’ve spoken with a few people with more modern NVidia GPUs that swear they’re awesome for video encoding. The performance of older cards varies. If you’re interested in picking up a used NVidia card check the wikipedia web page on NVENC as the table explains quite a bit about the actual graphics processors that support NVENC. I’ll reiterate, just because something is newer, doesn’t mean it’s better. Take the NVidia GT1030 2GB video card for example. Checking Techpowerup, the GT1030 uses a GP108 graphics core, which the wikipedia NVENC web page shows has no NVENC encoders available for. In our results the i7-4770 (non-K) with quicksync enabled beat out the i7-7700K without quicksync enabled, so just because something is old doesn’t mean it’s bad… with quicksync enabled the newer i7-7700K is more than 100 FPS faster, so this choice comes down to economics and the availability of similar hardware where you are.\nWhen encoding multiple files be prepared either to not get NVENC performance, or to individually add each file (babysit your computer). I prefer to batch everything and let the CPU encode everything at once. I have to imaging this is something that will be fixed in a later version of handbrake.\nWhether it’s the (.deb debian) repository of Handbrake vs the flatpak Handbrake, or just differences between Xubuntu and Linux Mint, Handbrake worked better under Xubuntu for queuing multiple files. It was simply less work, and less strain on the hands. I previously mentioned switching my home desktop to Linux Mint, that didn’t last long after I discovered this Handbrake issue. My home workstation is back running Xubuntu and will likely stay that way for the foreseeable future.\nSadly I didn’t have access to a lot of newer hardware, it would have been really nice to run the same tests on a modern Intel graphics card, or newer NVidia graphics card. I’ll continue to update this list as I have access to more hardware. I have more to say about encoding 1080p vs 4k, but that’s for a different post.",
    "description": "Hardware and Linux Distribution Differences This post covers a bunch of areas of media decoding and encoding that I’ve discovered over a number of years using Debian-based distributions like Xubuntu, and Linux Mint. Primarily I’ll cover some of the differences between Xubuntu and Linux Mint, how various hardware (CPUs and graphics cards) encode video, and some of the “gotchas” when it comes to different methods as they apply to Handbrake (software) and MakeMKV.",
    "tags": [
      "1080p",
      "4k",
      "Blu-Ray",
      "DVD",
      "Encoding",
      "Hardware",
      "Linux",
      "Media",
      "Handbrake",
      "Xubuntu",
      "Linux Mint",
      "FPS"
    ],
    "title": "Lessons learned encoding media under linux",
    "uri": "/posts/lessons_learned_encoding_media_under_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Media",
    "uri": "/categories/media/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Media",
    "uri": "/tags/media/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Xubuntu",
    "uri": "/tags/xubuntu/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Jazz Jackrabbit – an introduction Back in 1994 the World Wide Web (WWW) was just starting to catch on, mostly via a dial-up connection. Bulletin Board Systems (BBS) were starting to be on the way out, but at the time I was running a bulletin board for a local computer club. One of the attractions of bulletin board systems (besides online games/aka doors, message boards, and chatting) were the extensive “shareware” software collections. If you weren’t going to a computer store to buy software, you were probably calling a bulletin board to download shareware or freeware software. Shareware software became known as “try before you buy” software. In most cases software was fully functional, but limited in some way (for example: a game where you could play the first few levels, but if you wanted more, you had to send the shareware author money for the rest of the software).\nOne of the really popular games you could download from a bulletin board was the shareware version of Epic MegaGames’ Jazz Jackrabbit. Jazz was similar to the commercial game Sonic the Hedgehog in the sense that the idea was to speed through the level as fast as possible. In Jazz Jackrabbit you’re Jazz, a Jackrabbit who must speed through levels in order to rescue Eva Earlong, your girlfriend, from the evil turtle Devan Shell. On the way you blast through other enemies, pick up various weapons, and pass by game save points.\nJazz was pretty graphical for the time and had a fair amount of polish.\nOpenJazz OpenJazz was started on the 23rd of August, 2005, by Alister Thomson. Others later ported the projects to other operating systems and platforms. OpenJazz isn’t playable on it’s own, it needs either the shareware files or full files from Jazz Jackrabbit. It’s important to note that OpenJazz only works with Jazz Jackrabbit 1 files, files from Jazz Jackrabbit 2 will not work with OpenJazz. Additionally, I found some files, like the Holiday Hare shareware files resulted in the title screen looking a bit glitchy (this went away when I pressed ESC and started playing the game).\nOpenJazz has some issues, but these are mostly due to the fact that games back then didn’t autoscale to the current resolution. When I installed OpenJazz and launched it with Holiday Hare it launched at a very low 320×200 resolution. Thankfully the resolution can be adjusted in game, but adjusting the resolution doesn’t necessarily adjust all screens (the storyline screens for example stayed at the lowest resolution). There are work-arounds – I lowered the display resolution of one of my monitors to better match the game.\nOpenJazz also lets you run the game with a number of “switches.”:\nOpenJazz -f ~/PATH_TO_JAZZ_FILES The -f switch runs Openjazz in full screen mode. When running OpenJazz you have to specify the path to where the extracted Jazz Jackrabbit files are. OpenJazz can also take the following other switches:\n-window : start in windowed mode -m : start with muted audio -s : scale the window by a factor (1 to 4) -w, -l : directly load a specific world/level -q : no logging -verbose : log much more than the default logging -v : display the version of OpenJazz (and when it was built) -h : display help for OpenJazz I was not able to jump to a specific level using the -l switch, but when I tried I was using the Holiday Hare pack. I expect using something like the files from the full paid edition of Jazz Jackrabbit would have worked.\nInstalling OpenJazz on Xubuntu and Linux Mint OpenJazz is in the software repositories for Xubuntu 24.04.1. I also checked Linux Mint 22 and found the same openjazz package in Linux Mint 22. To install OpenJazz open a terminal (CTRL + ALT + T) and type:\nsudo apt install openjazz Note that when you install the OpenJazz software package everything has to be lowercase as the software package is named in lowercase and Linux is “case sensitive.” Sadly, the actual executable is a mix of upper and lowercase letters: OpenJazz, so when starting the game you have to capitalize both the O and J. Funny enough though you can read the manual (man page) by typing the lowercase name after man:\nman openjazz Starting the game As mentioned earlier, in order to play Jazz Jackrabbit, you either need the original game files, or one of the shareware files. I found the Holiday Hare files and extracted them to my ~/Downloads directory. (If you’re unfamiliar with Linux command line shortcuts, the tilde (~) symbol refers to your home directory. In my case /home/chaslinux. So ~/Downloads refers to a full path of /home/chaslinux/Downloads). The extracted directory was called Jazz95. In order for me to run the Holiday Hare files using OpenJazz, the full command was:\nOpenJazz ~/Downloads/Jazz95 Alternatively I could have typed the full path:\nOpenJazz /home/chaslinux/Downloads/Jazz95 Learning a bit about command line commands saves a lot of typing and makes life a lot simpler.\nRetro-rewind Jazz Jackrabbit is one of a number of “classic” games that are playable under Linux (albeit with a bit of effort). Among other classic games within apt repositories are Tyrian (opentyrian), Doom (various), Paradroid (freedroid), and Puzzle Bobble (as frozenbubble). I’m sure there are many more I’ve missed, and this excludes a lot of classic commercial games that are still selling via platforms like Steam. I picked up one of my favourite games of all time Heroes of Might and Magic III via Steam, and it’s fully playable under Linux via Proton… but that’s for another post.",
    "description": "Jazz Jackrabbit – an introduction Back in 1994 the World Wide Web (WWW) was just starting to catch on, mostly via a dial-up connection. Bulletin Board Systems (BBS) were starting to be on the way out, but at the time I was running a bulletin board for a local computer club. One of the attractions of bulletin board systems (besides online games/aka doors, message boards, and chatting) were the extensive “shareware” software collections. If you weren’t going to a computer store to buy software, you were probably calling a bulletin board to download shareware or freeware software. Shareware software became known as “try before you buy” software. In most cases software was fully functional, but limited in some way (for example: a game where you could play the first few levels, but if you wanted more, you had to send the shareware author money for the rest of the software).",
    "tags": [
      "Gaming",
      "Linux",
      "Software",
      "Steam",
      "Xubuntu",
      "Linux Mint"
    ],
    "title": "How to play Jazz Jackrabbit on Linux",
    "uri": "/posts/how_to_play_jazz_jackrabbit_on_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Software",
    "uri": "/tags/software/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: CLI",
    "uri": "/tags/cli/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Command Line",
    "uri": "/tags/command-line/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Shell Scripting",
    "uri": "/tags/shell-scripting/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Troubleshooting",
    "uri": "/tags/troubleshooting/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Introduction Recently I was checking out Youtube videos about a Linux-related program, and I came across a comment in one of the videos that I’ve seen before (I’m paraphrasing this to not identify the video or commenter):\nrandom comment on a Linux video: “Those commands don’t work. In Windows, you don’t have to write a book to install something. I’m going back to Windows.”\nThe comment isn’t a question, but a statement: Linux is difficult, Windows is easier.\nComments like this are not helpful because they lack context. They lack context because the comment didn’t include any information other than “those commands don’t work.” Was the commenter using the same Linux distribution? Was the commenter using the same version of the distribution? Did they spell the commands correctly? Were the commands typed in the proper case (upper case and lower case matter)? What was the error? Too many people give up early because they think their experience with something else is easier, but is it better?\nFor many years, I hated anything to do with cooking. Why would I want to learn to cook, when I could just buy something and microwave it? Cooking took too much time, and things often didn’t turn out - even following a recipe exactly.\nThis sort of parallel’s the commenter’s post in the sense that when I made an effort to do something, it never worked out for me. Then I met my wife, and she cooked for me, and I loved the food. I began to realize how much I missed home-cooked food. I started learning basic kitchen skills from videos. I started realizing some of the mistakes I was making. I was sure I was doing everything exactly as recipes perscribed, but I realized I wasn’t. Temperature was wrong, because stoves vary. Time was wrong, because of the same issue. Ingredients weren’t exactly the same, etc.\nSlowly, I started learning more and more kitchen skills. To be clear, I wasn’t inspired enough to be a chef (expert), but learning to cook made the process easier, and it felt a lot less like a chore. As a bonus, the quality of food I consumed got better.\nI was just thinking of another example. The simple act of launching a program, Audacity comes to mind since it works on both Windows and Linux. In both Linux and Windows you can create a shortcut on the desktop to click or double click to launch. This involves moving the mouse close enough to the icon then clicking on it. To launch audacity from a terminal in Xubuntu Linux, hold down the windows key and press T to launch a terminal session… start typing the letters aud, then press the TAB key to complete the filename. Hit enter and audacity launches (unless you have several other programs, like audacious…, etc., in which you just have to press TAB again to see which others begin with aud).\nBut more than this… there’s another advantage to launching programs from the command line, sometimes you’ll see error messages you wouldn’t see launching the program graphically.\nRecently I installed a program named planner on Xubuntu 22.04. Planner launched normally when I clicked through the menus and launched the icon. Nothing seemed out of place. But I then decided to launch it from the command line and noticed a message:\nFailed to load module \"atk-bridge\" Planner was working, but clearly something wasn’t 100%. There were several reddit, and other site posts that suggested trying things that didn’t work, but buried among those was the suggestion to install an “adaptor” program. In Xubuntu this turned out to be: libatk-adaptor.\nA bit more digging and this seems to be related to letting planner, a program that uses some older technology, work with newer software.\nYes, planner worked without needing to install this extra piece of software. But installing the software was simple:\nsudo apt install libatk-adaptor The next time I launched planner from the command line, no warnings, no issues. The lesson, sometimes the command line can give you more information about an error/issue. If a program is failing to launch from the graphical user interface, try opening a terminal (Windows key + T in Xubuntu) and running the command. If you’re not sure what the actual command name is right click on the item in the menu and select the Edit Launcher option. A new window will open up. In the new window the name of the command will be in the command section.\nFig 1. Mate Calc launcher information in Xubuntu Linux\nShortcuts make the difference In pre-Windows days, one of the most popular applications was Wordperfect for DOS. Wordperfect for DOS came with a template that fit around the function keys on a keyboard. That template contained “hot keys” for popular functions in Wordperfect. The fact that hot keys persist today in applications is a testament to the effectiveness of using hot keys.\nIt’s the same on the command line in Linux. Hot keys and shortcuts really make life simpler. I almost never move the mouse up to the menu, click on it, then click Terminal Emulator. It’s far easier for me just to hold down the Windows key on the keyboard and press T.\nTricks like filename completion (using the TAB key) really save a lot of time once you get used to using them. I’ve also discovered new commands, and remembered commands I used to use thanks to using TAB completion. TAB completion works like this: You start to type the first few letters of a command then press the TAB key, if nothing happens, then likely there is another command that begins with those first few letters. If you press the TAB key a second time it will display all the commands that begin with those first few letters. If there is no other command that starts with those few letters pressing TAB once will complete the whole command name. For example:\nOn the Linux Mint XFCE 21.3 system I’m on now if I type the letter f in a terminal and press the TAB key, nothing happens. If I press the TAB key a second time I’m prompted (y/n) if I want to see the 134 commands that begin with f.\nFig 2. F + Tab - display 134 possibilities (y/n)\nIf I then type ff and press TAB nothing happens. But if I press TAB a second time I see 4 commands displayed (ffmpeg, ffmpegthumbnailer, ffplay, and ffprobe).\nFig 3. FF + TAB results\nSimilarly, if I type ffp and press TAB, still nothing happens. This is because there are two programs installed on my system that begin with ffp (ffplay and ffprobe). The moment there’s a different letter TAB will complete the filename. So when I typed ffpl and pressed TAB, TAB completion finished off the command adding the ay. This might seem like a lot of effort for two letters, and in this case it is, but some commands are a lot longer to type out, and TAB completion comes in really handy when it comes to those commands.\nFig 4. FFP + TAB results\nThe command uncompress is a good example of a command where you can save time by typing unc then pressing TAB to complete the ompress part of the command.\nCombined with graphical user interface shortcut keys, command line shortcuts are really handy.\nAnother great command line shortcut is to use the up/down arrow keys. These keys cycle up/down through your command history. If you’ve typed something particularly long and need to repeat it, pressing the UP arrow a few times is often quicker than typing out the whole command. Typing the word history in a terminal will let you look at the last 200 commands you’ve typed in the terminal. These are the commands the UP/DOWN arrow keys will cycle through.\nFig 5. History results (using up/down arrow keys)\nHow do you know what shortcut keys do what? Many Linux distributions have graphical user shortcut keys stored within a keyboard program. In Linux Mint XFCE if you open the “whisker” (XFCE) menu and type keyboard into the menu, then click the keyboard program it will bring up a window/program with 3 tabs (behaviour, Application Shortcuts, Layout). Clicking on the Application Shortcuts tab reveals some of the shortcuts that can be used within Linux Mint XFCE. The “Super” key refers to the “Windows” key on some keyboards. Pressing Super + P on Linux Mint XFCE displays the Display program, letting you control things like your monitor’s resolution. This is a lot quicker than clicking the Whisker menu searching the menu for the Display program, then launching it. Most of the shortcuts can be changed within the keyboard program, so you can make key combinations that make more sense to you… just be sure to pick combinations that are not already being used by another shortcut.\nFig 6. Keyboard/Application shortcuts\nDitching the ALT key There is another key we have to talk about, the ALT key. The ALT key is special is most Linux distributions. If you’ve ever tried using the Unity game engine, or another program that makes heavy use of the ALT key, you might have been met with some frustration, as some Linux distributions, like Linux Mint XFCE/Xubuntu use the ALT key for Accessibility options. But it’s not mapped under the Accessibility, nor the keyboard program. Instead look to the Window Manager Tweaks program. Type Window Manager Tweaks in the whisker menu in Linux Mint XFCE/Xubuntu and then launch the program. The Window Manager Tweaks has 6 tabs across the top. Select the Accessibility tab. In this tab the key used to grab and move windows is set to the ALT key. If you play to develop games under Linux using the Unity game engine, or another engine that makes heavy use of the ALT key, change this setting. What do you lose by changing this? The ability to move windows that are too big for your screen. If you’re screen resolution limited, using something like a 1366×768 display, you might want to keep/change the setting as holding ALT and click dragging a window will let you move it to where you can see any buttons at the bottom.\nFig 8. Changing the ALT key behaviour\nBut the terminal is a scary place… It’s really not scary. Start by learning a few basic commands like ls, cd. Learning something new takes time. Painters don’t become a master the first time they pick up a paintbrush. Learning to ride a bike, or drive a car takes a bit of practice. But once you learn some of the shortcuts, using the terminal makes some tasks a whole lot easier than clicking around. My favourite task to do in a terminal is to update my Xubuntu and Linux Mint XFCE systems. To do this I hold CTRL + ALT + T to bring up a terminal, and in that terminal I type:\nsudo apt update \u0026\u0026 sudo apt upgrade -y When I’m typing this in the terminal I’m really typing sudo apt upd (+TAB) \u0026\u0026 sudo apt upg (+TAB) -y. Ignore the brackets and +, I’m hitting the TAB key in those spots to save myself 7 keystrokes (ate and rade). I could click on the Whisker menu and type upd, then click the Update Manager program, but the update manager program takes time as it needs to update the cache/list of available updates. There’s no delay like this on the command line as the first command, update, does that for us as the two commands are running. The \u0026\u0026 after the initial update allows us to run the second program after the first is done.\nLife isn’t all perfect on the command line as this example falls down a bit in that thanks to Linux distributions branching out to use other methods of installing (like snap and flatpak), means extra steps if you want to update everything. (We’d have to add something like \u0026\u0026 flatpak update to the end of the command if we wanted to do more on a Linux Mint system). But the time savings is there, and in my experience learning shortcut keys really makes life a lot simpler.",
    "description": "Introduction Recently I was checking out Youtube videos about a Linux-related program, and I came across a comment in one of the videos that I’ve seen before (I’m paraphrasing this to not identify the video or commenter):\nrandom comment on a Linux video: “Those commands don’t work. In Windows, you don’t have to write a book to install something. I’m going back to Windows.”\nThe comment isn’t a question, but a statement: Linux is difficult, Windows is easier.",
    "tags": [
      "Linux",
      "Xubuntu",
      "Linux Mint",
      "Shell Scripting",
      "Troubleshooting",
      "Command Line",
      "CLI"
    ],
    "title": "Why command line skills are important - Troubleshooting...",
    "uri": "/posts/why_command_line_skills_are_important/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Initial look at artificial intelligence We might be a bit late to the game, but I’ve started looking at what we need at the Computer Recycling Project to run artificial intelligence models locally (on the machine, versus on the server) under Linux. The Ollama project makes it very easy to install a number of artificial intelligence models under Linux.\nOnce ollama is installed you can download a model by typing:\nollama pull \u003cmodel name\u003e So if you wanted to pull Llama 3.2 you would type:\nollama pull llama3.2 This command simply downloads the model. To run the AI with the model type:\nollama run \u003cmodel\u003e Again for llama3.2 the command would be:\nollama run llama3.2 This of course assumes you’ve downloaded the model first. A list of models ollama can work with can be found on the github ollama web page at: (https://github.com/ollama/ollama) Some models have different strengths. For example: codellama is suppose to be better at writing code than the regular llama 3.2 model.\nMy brief experience I’ve only spent a couple of days with Llama 3.2 and I’ve already noticed some issues. Llama isn’t bad, but you cannot trust that it’s correct on things. For example, I have a XEON E5-2690 V2 CPU that llama 3.2 thought was an 8 core 16 thread CPU, when in fact it’s a 10 core 20 thread CPU. I corrected llama on some mistakes it make, but I found that when making some comparisons llama will sometimes revert back to the old information it had about something. More infuriatingly it might state the new information, but further down suggest something that’s bound to old information it has.\nI also asked llama 3.2 to write a bit of GML (GameMaker Language) and it was able to write a bit of code. Asking for bits of small code seems mostly okay. I was very surprised when I asked llama 3.2 about the differences between the Brother ScanNCut SDX125e cutting machine, Cricut cutting machines, and Silhouette cutting machines, it gave me a pretty good list of advantages and disadvantages of each.\nThe last thing I experienced has to do with the speed of running llama 3.2. Having an Nvidia GPU really seems to help – a lot. The Intel Core i7-4790 with 16GB of RAM and a 4GB Nvidia Quadro P1000 runs models much faster than an i7-7700K with 16GB of RAM and an AMD RX580 8GB graphics card – at least in my testing. Having an Nvidia GPU really helps.",
    "description": "Initial look at artificial intelligence We might be a bit late to the game, but I’ve started looking at what we need at the Computer Recycling Project to run artificial intelligence models locally (on the machine, versus on the server) under Linux. The Ollama project makes it very easy to install a number of artificial intelligence models under Linux.\nOnce ollama is installed you can download a model by typing:\nollama pull \u003cmodel name\u003e So if you wanted to pull Llama 3.2 you would type:",
    "tags": [],
    "title": "Simple Artificial Intelligence on Linux",
    "uri": "/posts/simple_artificial_intelligence_on_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Suspend doesn’t work on some Linux distributions – Lenovo Yoga S1 Our experience with Linux Mint XFCE has been pretty good so far at The Working Centre’s Computer Recycling Project, but we recently ran into an issue where a couple of Lenovo Yoga S1 laptops refused to suspend when the suspend button was clicked.\nNow before someone goes on about Linux, I want to point out a couple of things:\nThe issue does not happen in Fedora 41 Workstation, nor does it happen in Xubuntu 24.04.1. Windows has it’s own issues with software that should work, but doesn’t because of some quirk/bug (having been with the project for 23 years I’ve seen a lot of issues on different OS’s) There are several threads relating to the issue, but the one that worked (with some modifications) for us was: (https://forums.linuxmint.com/viewtopic.php?t=391671)\nTest, test, and more testing We tried several different potential solutions to fix the issue before finally finding the thread above. Things we tested were:\nUpdating all software Changing to the latest kernel available for Linux Mint 21.3 (virginia) Installing Linux Mint XFCE version 22 (Wilma) In the BIOS changing USB so that ALWAYS ON USB was disabled. Other threads gave a hint as to the culprit, and actually mentioned the solution, but didn’t mention how they went about the solution: (https://forums.linuxmint.com/viewtopic.php?t=411541)\nWe also tried Fedora Workstation 41 (which, by the way looked pretty stunning on the Yoga S1), and Xubuntu 24.04.1, both of which suspended properly when we clicked the suspend button. We also confirmed that the issue did not happen on the dozen other models of laptops we had on display with Linux Mint XFCE 21.3/22 installed. (So this wasn’t a general bug across other Lenovo ThinkPads and Linux Mint)\nXHC – The culprit Both of the laptops we ran into this issue on were Lenovo ThinkPad S1 Yogas with Intel Core i7-4600 CPUs, 8GB DDR3 SO-DIMM RAM, and 256GB Samsung SSDs. The S1 Yogas are nice little laptops with a 1920×1080 resolution screen, and a pen that can be used with the touch screen.\nThe first URL mentioned at the top mentions both XHC and XHCI. The thread makes suggestions that don’t work on the Yoga S1 as one of the methods results in a permission error, and the other indicates XHCI is the issue. On the Yoga S1s we have at the shop XHC is the culprit.\nSolution – Creating a startup script to disable XHC, enabling, and starting the script on startup\nThe solution that worked for us is a combination of what both Karsti and t42 wrote in the thread. Create a text file called usb-wakeup.service. In that file paste the following:\n[Unit] Description=Disable wakeup events [Service] ExecStart=/bin/bash -c \"echo XHC \u003e /proc/acpi/wakeup\" Type=oneshot [Install] WantedBy=multi-user.target The main difference between this and t42’s script is the changed ExecStart line. t42’s example uses XHC0, instead of XHC. This doesn’t work for our S1 Yoga.\nNext be sure to set execute permission on the usb-wakeup.service file:\nchmod ugo+x usb-wakeup.service Once you’ve created the file copy it to the /etc/systemd/system directory:\nsudo cp usb-wakeup.service /etc/systemd/system/ Finally, enable the service and start it:\nsudo systemctl enable usb-wakeup.service sudo systemctl start usb-wakeup.service Now suspend should work. Reboot, and as long as you’ve run the enable line, the fix should work every time. If you’re using a different machine, XHC might be XHC0. See the second URL mentioned above for the complete thread.",
    "description": "Suspend doesn’t work on some Linux distributions – Lenovo Yoga S1 Our experience with Linux Mint XFCE has been pretty good so far at The Working Centre’s Computer Recycling Project, but we recently ran into an issue where a couple of Lenovo Yoga S1 laptops refused to suspend when the suspend button was clicked.\nNow before someone goes on about Linux, I want to point out a couple of things:",
    "tags": [],
    "title": "[Fix] Suspend doesn't work on Linux Mint XFCE Lenovo Yoga S1",
    "uri": "/posts/suspend_doesnt_work_on_linux_mint_xfce_lenovo_yoga_s1/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: NAS",
    "uri": "/tags/nas/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Network Attached Storage",
    "uri": "/tags/network-attached-storage/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Networking",
    "uri": "/categories/networking/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Networking",
    "uri": "/tags/networking/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "It lives, it dies! Our new TrueNAS server is up, and all the hardware is working, but not without some hiccups on the way. After taking a lot longer to build than expect, I was so happy the other evening when I posted about the successful Power On Self Test (POST), and the new RAM (32GB) being properly detected. Exhausted at the end of the day I left the drives disconnected and the video card out.\nThe next day I’d planned on connecting the drives, installing TrueNAS, then maybe adding the video card. Things didn’t go as expected… The night before I’d moved the TrueNAS server in to another room. This move must have jostled things because the next day, after work, I powered on the system and … no video. I tried pulling the RAM and individually placing each stick in, swapping HDMI cables, trying different sources on the television, adding the video card, and resetting the BIOS, nothing helped. To make matters worse, while the motherboard had a speaker header, I had no PC speaker on me to plug into the motherboard for better diagnosis. I was gutted thinking that perhaps the wonderful Corsair 750W PSU had issues. Thankfully, this wasn’t the case. In a last stitch effort I reseated the AIO CPU water block, and voila, the screen sparked to life!\nDeciding to go lower power, a good choice. In my previous posts I mentioned that the new ASUS Prime motherboard actually had an i7-7700K, a pretty awesome CPU for it’s time. But that CPU runs at 95W, and trying to think more forward, my wife and I not only want to simplify, we want to also try to save energy. While the i3-7100 cannot compare to the i7-700K for gaming performance, it seems (so far) like it’s more than capable of handling the load of transferring data to our NAS. With a TDP of 51W it’s going to use quite a bit less power than the 7700K would, and I haven’t seen it go much above 20% use transferring terabytes of data over.\nFig 1. Creating the TrueNAS datasets\nWhat did surprise me was the amount of RAM TrueNAS uses… all of it! Almost all of the 32GB of RAM is being used by TrueNAS, most of it for a ZFS (Zettabyte File System) cache. So far I’ve transferred around 7TB of data from our old media centre (via the backup Dell T110 TrueNAS).\nMan in the middle, slow SMB? I started transferring data via my desktop workstation. Sitting in front of my desktop I fired up Filezilla, and entered the settings for our temporary backup TrueNAS server, the Dell T110. In Filezilla I used SFTP to transfer data from the T110 to my workstation. I then entered the settings for the new custom TrueNAS server, and transferred files from my workstation to the new server. While I was getting transfer speeds of around 110 Mb/s, this man in the middle approach wasn’t really working because my desktop workstation has limited space (500GB), so I’d have to transfer small batches of data.\nI set up SMB shares on both TrueNAS servers so I could drag and drop files between the two servers. File transfers slowed considerably, to around 55 Mb/s. I’m not sure if this is TrueNAS’s implementation of SMB, the fact that I was still using my workstation to do the drag and drop, or something else. Yesterday I looked to see if I could find something to do SFTP from one machine to another. Yes, I know I could use the terminal and sftp itself, and this is probably what I should have done, but I wanted to see if I could do it graphically (if I need to show someone else, I want to make it as simple as possible). I found a useful, but ill-named tool: gigolo. Gigolo lets you mount SFTP shares and graphically transfer between the two shares. I tried Gigolo at work, but found it has really terrible performance (around 15 Mb/s)transferring between 2 machines that are not the machine you’re currently on. I tried a few different computers, all with Gigabit LAN connections, on the same subnet, and close to one another. It’s convenient, but even the SMB performance was a lot better.\nI’m not sure why my SMB performance is slow as I’ve seen reports of people getting 90 Mb/s+ via gigabit LAN. It will matter less after today as almost all the data on our old Dell TrueNAS (the backup for our media centre) will be copied over.\nFig 2. Mixed stack of backup drives from the backup Dell T110 NAS\nThe job isn’t done yet! Back when I first noticed our KODI media centre was hovering around 93% disk space I started backing up new media to 3.5″ drives via a dock. This allowed me to shuck the cases and put the video discs in a binder that holds 250 discs. There is still probably 2-3 TB more data to copy over from these disks, but I can just connect those directly to the TrueNAS server and transfer over USB 3.0.\nAt some point I’m going to look at installing Jellyfin on the TrueNAS server, but I have a lot to learn about TrueNAS itself before doing this. I also haven’t installed the GTX 970 4GB graphics card yet. I’m still wondering about whether I should or not. I may end up using it for a older gaming build in the old Corsair Spec 02 case with that i7-7700K. That might make for a nicer old gaming machine for someone.\nThe NAS build is done for now, I probably won’t be writing much about it in the near future, but there may be an article or two if I discover something particularly interesting.\nWhat’s next? In terms of the NAS, building the NAS with a RAID-Z1 wasn’t ideal. While I do still have the Dell T110 as a backup server, it sits in storage - it’s backup only in the sense that I could use it to offload some data. But now that I have more than 20TB of potential storage on our main TrueNAS server I need larger drives for the backup server. I’m thinking to buy some inexpensive used NAS-grade drives from a reseller. After buying these I can port the data over to the backup server (because I’ve added a lot more data since), and add yet another Seagate 8TB Ironwolf I’ve since picked up.",
    "description": "It lives, it dies! Our new TrueNAS server is up, and all the hardware is working, but not without some hiccups on the way. After taking a lot longer to build than expect, I was so happy the other evening when I posted about the successful Power On Self Test (POST), and the new RAM (32GB) being properly detected. Exhausted at the end of the day I left the drives disconnected and the video card out.",
    "tags": [
      "TrueNAS",
      "NAS",
      "Network Attached Storage",
      "Storage",
      "Hardware",
      "Linux",
      "Media",
      "DVD",
      "Blu-Ray",
      "Networking"
    ],
    "title": "Our TrueNAS Server",
    "uri": "/posts/our_truenas_server/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Storage",
    "uri": "/tags/storage/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: TrueNAS",
    "uri": "/tags/truenas/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Most of the hardware is assembled The past few weeks have been extremely busy, so I knew last night would probably be the only time I would get this week to work on the NAS. I’m glad I started building the NAS last night as it took much longer than anticipated. I finally finished the build at 10pm last night (and it’s still not quite complete).\nFig 1. I used an Intel Core i3-7100 CPU for lower power consumption\nUsing parts of our old KODI media centre Part of the reason the build took so long was that I needed to use several parts from our existing KODI media centre. My wife and I are trying to make our space look less cluttered. And while the Corsair Spec 02 case our existing media centre was in really wasn’t a big eyesore, we’ve been loving the look of Tiny Form Factor PCs. Lately, the Computer Recycling Project has seen a number of TFF PCs come in, with decent specifications too (7th gen Dell Optiplex 3050s). One of these looks a whole lot better under a television than the Spec 02 machine. Because the NAS is only 4 drives, I could have built it in the SPEC 02 case, but there were several reasons why I didn’t:\nThe motherboard in that build didn’t have a back plate, and while this doesn’t affect the performance, have that much more open space allows for a lot more dust to settle in the system. There’s not much space for drives, and in that cramped space the 4 drives would likely heat up much quicker. I have more media than space, even with the new drives I’m not sure the additional space will stay free for very long. Being able to expand in the future (even if I have to copy to dozens of other smaller drives and rebuild) is important. With that in mind I bought a Fractal Design Refine 5. Cases that support more than 2 x 3.5″ drives are really hard to find. Even at the Computer Recycling Project we rarely see cases with lots of drive space and all the equipment to mount those drives. The Refine 5 wasn’t cheap ($165 CDN), but at least it was on sale when I bought it.\nIn my last post I mentioned I planned on using another, untested motherboard, an ASUS Prime Z270-A. That motherboard actually came with an Intel Core i7-7700K CPU, but I decided against using that CPU as it draws 40 watts more than the Intel Core i3-7100 in our existing media centre. I also pulled the Corsair 750W power supply, RAM, and the Corsair H100i AIO. Pulling out the power supply and AIO turned out to be more time consuming than expected as everything was a pretty tight fit in the AIO.\nThe Fractal Design Refine R5 – good, but far from perfect I really like the look and design of the Fractal Design Refine 5. It’s a tragedy that case manufacturers are opting to build less functionaly cases with RGB lighting, instead of including actual functionality (additional drives, 5 1/4 inch bays, etc.). Don’t get me wrong, I like RGB lighting, but I’ll take the added functionality over RGB lighting and clear side panels any day.\nHere are some things that annoyed me about the Refine 5:\nThe manual has great pictures, but little explanation. For the most part things are clear from the pictures, but having never built in a similar case things like the fan control connection were not as clear as could have been. Some things are out of order (optional steps). If you’re planning on building in this case with an AIO, remove the top panels BEFORE you put the motherboard in. It took me nearly 20 minutes to pinch those clips that have to be pinched in order to remove the top back panel. If the case was still empty this wouldn’t have been an issue. Some sort of forewarning, like “if you’re planning to use an AIO, remove the top panel(s) first)” would have been really helpful. A couple of spaces are tight. In order to put the 8 pin power connector through the top left I had to separate the connector into it’s 2 x 4pin parts and put them through the channeling, then reconnect them before attaching the connector to the motherboard. A bit more routing space would have been handy. Also, the fan connector on the back, and for my AIO, both use a SATA power connector which is pretty wide and difficult to keep flat against the back plane. My Corsair PSU has additional cables for molex, so I had to route them under the drive bays. I guess this case is really better if you have a modular power supply with separate cables. There was enough space to route/hide everything, but if I add more drives I’ll be changing power supplies. No USB-C. While I don’t use this much, it would have been nice to have on the Refine 5, or at least all USB 3.0. But there are good things about the Refine R5 There are some things I really appreciated about the case:\nLots of space for drives, and well laid out. There’s actually even more space for drives using optional components, but I have no plans to go that crazy. I LOVE the trays Fractal Design chose. These trays proved really helpful as one of my Seagate Ironwolf 8TB drives (ST8000VN002) was not like the others (ST8000VN004). That first drive has fewer mounting holes on both the sides and bottom. Being able to adjust where the drive is mounted in the tray made it possible to reasonably mount the drive as I wanted in the case. The channeling is among the best in cases I’ve built in, with the exception of routing the 8 pin power cable I mentioned earlier. Construction, it’s just a quality case. Things still to do I didn’t get to everything last night. It was almost 10pm when I finally booted the system for the first time to a successful POST. The POST showed all 32GB of RAM, which was my main concern at 10pm. I didn’t get the chance to connect all the hard drives as it was too late in the evening. Part of the reason I didn’t connect them up was the fact that all the SATA data cables I had on hand were different, and I wanted some consistency. Luckily, there’s Computer Recycling, and cables are cheap ($0.50/each). I also didn’t put the Gigabyte GTX970 4GB video card in the system. When I tested for POST I used the ASUS Prime’s onboard video, which appeared to work just fine. I know the GTX970 works, as it was the card we used in our KODI media centre.\nFig 2. Gigabyte GTX970 4GB video card\nThis evening my better half and I have some work to do, but I’m hoping to finally connect up the drives and install TrueNAS. I’m still torn whether to put the GTX970 in the build or not, it means more draw on the 750W power supply, but I believe software like Jellyfin benefit from the 970.",
    "description": "Most of the hardware is assembled The past few weeks have been extremely busy, so I knew last night would probably be the only time I would get this week to work on the NAS. I’m glad I started building the NAS last night as it took much longer than anticipated. I finally finished the build at 10pm last night (and it’s still not quite complete).\nFig 1. I used an Intel Core i3-7100 CPU for lower power consumption",
    "tags": [
      "TrueNAS",
      "NAS",
      "Network Attached Storage",
      "Storage",
      "Hardware",
      "Linux",
      "Media",
      "DVD",
      "Blu-Ray",
      "Networking"
    ],
    "title": "Building the NAS - hardware hiccups",
    "uri": "/posts/building_the_nas/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Computer Refurbishing",
    "uri": "/categories/computer-refurbishing/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Cleaning",
    "uri": "/tags/cleaning/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Computer Recycling",
    "uri": "/tags/computer-recycling/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Computer Refurbishing",
    "uri": "/tags/computer-refurbishing/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Lenovo",
    "uri": "/tags/lenovo/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Past Isopropyl is a great way to clean up a lot of plastic, but I found that while it’s helpful for removing grime, caked on stickers (Goo Gone), and other crud, it doesn’t always leave a nice finish. A few years back a volunteer at the Computer Recycling Project mentioned interning at a small computer store where they used Mr. Clean Magic Erasers to clean-up the top of ThinkPads. True to what he said, Mr. Clean Magic Erasers do seem to be a pretty good job on the top of ThinkPads.\nThe proof The image at the start of this post shows a pretty dirty ThinkPad X220 laptop. There are fingerprings, dust, and flecks of something on the top of the laptop. While you can buy Mr. Clean Magic Erasers from Dollarama (our project has in the past), they tend to cost more than buying a 4 pack of Javex Easy Erasers. At $1.25CDN for 4 Easy Erasers, I thought we’d pick them up to see if they matched up against the Mr. Clean Magic Erasers – and for the most part they did.\nUsing the Easy Erasers Both the Mr. Clean Magic Erasers and the Javex Easy Erasers need a bit of water applied to be effective. User a little bit of water – too much water and water might run down the sides and inside the laptop. Make sure the laptop is off, and the battery is removed (if you’re using a newer model with an internal battery, make sure you’re not powered on – just in case water leaks inside). Apply firm pressure, but not enough to cause the Eraser/sponge to squish down.\nThe results are great The ThinkPad now looks a lot better than it did.\nFig 1. Clean Lenovo ThinkPad X220 \u0026 dirty Javex Easy Eraser\nMr. Clean Magic Eraser vs Javex Easy Erasers Besides the obvious cost difference, Mr. Clean Magic Erasers tend to have ridges or lumps. Some might suggest the Mr. Clean hold up better, but my experience is they both work well for the job provided you’re using light pressure. I’ve had both types of Erasers crumble when applied to other surfaces with a lot of pressure. At home I have a few Mr. Clean Magic Erasers, but I think the Javex Easy Erasers are overall the better deal for our purpose/quantity needed at work.",
    "description": "Past Isopropyl is a great way to clean up a lot of plastic, but I found that while it’s helpful for removing grime, caked on stickers (Goo Gone), and other crud, it doesn’t always leave a nice finish. A few years back a volunteer at the Computer Recycling Project mentioned interning at a small computer store where they used Mr. Clean Magic Erasers to clean-up the top of ThinkPads. True to what he said, Mr. Clean Magic Erasers do seem to be a pretty good job on the top of ThinkPads.",
    "tags": [
      "Computer Refurbishing",
      "Computer Recycling",
      "Hardware",
      "ThinkPad",
      "Lenovo",
      "Cleaning"
    ],
    "title": "Simple way to clean a Lenovo ThinkPad Case",
    "uri": "/posts/simple_way_to_clean_a_lenovo_thinkpad_case/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: ThinkPad",
    "uri": "/tags/thinkpad/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: KODI",
    "uri": "/tags/kodi/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Media Centre",
    "uri": "/tags/media-centre/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: TFF",
    "uri": "/tags/tff/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Moving more to a low-power solution Several months back I replaced the motherboard in the KODI media centre PC that sits in our living room. For many years our media centre has been rocking a Gigabyte motherboard with a second generation Core i7-2600 CPU. The Core i7-2600 came out in Q4 of 2010, making it almost 14 years old at the time I’m writing this. Still, it’s not a bad CPU. For several years it was the system I was compressing our movie collection on as the A8-5600K 4 core APU that was in my workstation (at the time) had about half the performance of the i7-2600. But about six months ago I replaced the CPU and motherboard with a still old, but more modern solution, a MSI motherboard and an Intel Core i3-7100.\nThe Core i3-7100, despite being 7th generation, still doesn’t quite have the multi-core performance of the i7-2600, at least in synthetic benchmarks, but it’s only about 19% less, and manages that on only 51W of power compared to 95W for the i7-2600. Sadly the motherboard and CPU combination did not come with a backplate, so the setup looks a bit jank. I’ve since bought another motherboard (ASUS), but it needs a bit of testing before I go replacing the MSI board.\nRAM Upgrade When I bought the MSI motherboard, I bought it thinking I had DDR4 RAM kicking around the apartment. I did, but it was only a mismatched pair of 4GB sticks of RAM (8GB total).\nFig 1. The old mismatched RAM in our KODI media centre\nLast weekend I picked up a couple of T-Force DDR4 Delta RGB sticks of RAM (2 x 8GB) to up the RAM to 16GB. Initially I thought about picking up 32GB, but we’ve been on vacation, so prioritizing what we’re spending on, I picked up the 16GB kit with the knowledge that the 4 slots on the ASUS board would let me move to 32GB by buying another 16GB kit in a few weeks. The T-Force RAM was on sale for $45CDN, not bad considering 2 x 8GB GSKill DDR3 sticks cost $189CDN new back in 2013.\nRGB was not the reason I bought the T-Force RAM. While there were 16GB kits slightly less expensive ($5 less), the T-Force RAM had a higher clock speed than either of the other kits on sale.\nFig 2. T-Force 16GB (8GB x 2) DDR4 kit - the new RAM\nSimplifying, and storage At one time our living room was packed with devices and media. Connected to the computer and television was a 5.1 surround sound Sony receiver, and the media centre stand was packed with DVDs, Blu-rays, and other physical media, plus several other devices.\nAs my wife and I age, we find ourselves wanting thinking about the fact that when we next move, we don’t want to have to lug around large surround sound systems, or look at clutter. Lately we’ve been purging, rather than adding things to our living space.\nI’ve also noticed we need more drive storage. Currently our media centre has a 500GB Seagate boot SSD, and 2 x 8TB Seagate Ironwolf hard drives. The drives are not in a RAID configuration, but the second drive is a backup for the first. Sunday, at 2pm in the morning, a cron job runs rsync to synchronize changes from the first drive to the second. While we have 2 x 8TB drives, we’re really only using 8TB. 4TB drives are really the sweet spot then it comes to buying new drives, a 4TB (CMR) Ironwolf Pro is currently only $133, but this isn’t nearly enough storage. And to be clear, it’s a Pro drive, vs the non-pro 8TB for $245 (currently). Ideally we would mirror the 8TB drives, but this would mean shelling out well over $500 for 2 drives. I expect that within the next several months the cost of drive storage will go down as both spinning rust and solid state drives continue to get bigger, so I’m loathe to buy 2 drives at once.\nWe also need more storage for things like our phones and cameras. Having big drives isn’t just about our media centre anymore, which made me rethink our living room.\nFig 3. Side view of the media centre with the new RAM\nWhile having a PC with glowing RAM is cool, I’ve been thinking our media centre PC should really transition into a TrueNAS server. Transitioning to TrueNAS would mean that I could do a RAID Z1 configuration with 3 drives, where two act as 16GB with one drive as parity. This would give us a bit more space for awhile. I’m still not convinced it’s enough, but it’s enough for now. This PC would then get tucked away in a less visible area.\nIn the living room we would use the Tiny Form Factor Lenovo PC pictured on the second glass layer in the first photo. This PC would replace our current KODI media centre and would use an NFS-mounted share (from the hidden TrueNAS server) for the media. I’ve tested NFS shares in the past and they’re plenty fast. And while this seems like we’re complicating things by adding a machine, since this machine is already being used for another purpose, we’re simply re-purposing it, and unifying our backup/media storage on the server.\nFuture upgrades More 8TB drives are the biggest hurdle at this point. The Corsair Spec01 case only has space for 4 drives, so if this ever evolves, it will mean a case upgrade. Sadly, case manufacturers don’t really seem to be manufacturing cases with 3 1/2 inch drive support anymore. Even worse, almost no one makes a case with a 5 1/4 inch drive bay, it’s all mostly old stock. Things like my 3 bay Blu-ray ripping (I’m using a Antec Three Hundred Two case) workstation, are becoming less and less possible without using old stock.\nAnother 16GB kit would be the next upgrade after adding more drives. The final couple of bits in our media centre puzzle would be a sound bar and switching out our old 42″ Samsung TV (which is several inches thick). The television is 1080p and has been a great TV, so there’s no need to switch it out. I’m really not that enamoured with 4K, and last year I bought a 4k monitor for my workstation, so if I ever feel the need to watch a 4k movie, I just need to go to another room. The switch would be more about mounting the television to the wall, which isn’t something I want to do with this old TV, and would be a lot more likely when we move – maybe a couple of years. It’s the least priority on our list – and ranks lower than buying a nice carpet for the living room.\nFig 4. Closeup of our old media centre\nInstead of having a big chonky media centre, I prefer the small Tiny Form Factor PCs in our living room. I’ve always been a fan of the “modern living room” look, but getting that way with all the junk we’ve collected over the years is hard. For now, our KODI media centre is still a media centre, but once I’ve added at least one more drive then I’m going to switch the system to a TrueNAS server.\nI haven’t decided yet if I’m going to switch to the ASUS board, as there may be some clearance issues with the Corsair H10 cooler and the size of the built-in backplate on the ASUS board, but I expect it will work. If not, I might be on the hunt for a new case too.\nWe’ve since swapped the big case for a Tiny Form Factor PC (the same as can be seen to the right of the title image). The TFF PC runs Xubuntu and KODI with shares mounted from our TrueNAS server.",
    "description": "Moving more to a low-power solution Several months back I replaced the motherboard in the KODI media centre PC that sits in our living room. For many years our media centre has been rocking a Gigabyte motherboard with a second generation Core i7-2600 CPU. The Core i7-2600 came out in Q4 of 2010, making it almost 14 years old at the time I’m writing this. Still, it’s not a bad CPU. For several years it was the system I was compressing our movie collection on as the A8-5600K 4 core APU that was in my workstation (at the time) had about half the performance of the i7-2600. But about six months ago I replaced the CPU and motherboard with a still old, but more modern solution, a MSI motherboard and an Intel Core i3-7100.",
    "tags": [
      "KODI",
      "Media Centre",
      "Media",
      "DVD",
      "Blu-Ray",
      "Hardware",
      "Linux",
      "Computer Refurbishing",
      "TFF",
      "TrueNAS",
      "XBMC",
      "Xubuntu"
    ],
    "title": "Transitioning our KODI media centre",
    "uri": "/posts/transitioning_our_kodi_media_centre/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: XBMC",
    "uri": "/tags/xbmc/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Note: This is an older post, reposted from the old web site. The project has since mostly switched to Linux Mint XFCE versions 21.3 (Virginia) and 22.1 (Xia). We still have Xubuntu 24.04.2 on our PXE server, but only install it on request. Our checklist has evolved and we’ve separated some steps into other checklists. See my github repositories for more info.\nWorkstation class hardware at a deeply discounted price Every now and then the Computer Recycling Project at The Working Centre gets a really interesting piece of hardware donated. As a not-for-profit project, most of our equipment is aimed at people who are lower income. This generally translates into lower prices, even for some equipment others would list for a lot more. But that doesn’t mean the project just wipes the machines, installs Linux, and dumps the equipment on a sales shelf… often equipment requires a little, or a lot more work.\nBeyond the checklist When Computer Recycling receives a computer, we normally either remove the hard drive and replace it with an already wiped drive, or wipe the drive on the spot in the case of solid state storage. Every computer that gets refurbished at Computer Recycling goes through a frequently changing checklist that’s broken down into a number of categories:\nComputer Externals : the steps in this stage are mostly to determine if the computer is worth building. First Boot : at this stage we turn on the computer, boot to our network server, and check that all fans are working. Computer Specifications : using software on our PXE network boot server we check to make sure the system meets our minimum build specifications (currently 3rd gen i-Series with 8GB RAM). Memory Test : all computers undergo a RAM test using Memtest86+ version 6.2. Once all RAM passes we move on to the next step. Any failed RAM sticks are replaced and the system is retested. Drive Testing : it’s not enough for us to just wipe a drive, we always test, wipe, and re-test after a wipe. Amy drives with reallocated sectors are replaced. This means we sometimes scrap potentially usable drives, but better safe than sorry. OS Installation : at this point we PXE boot and install Xubuntu Linux 22.04 from our network installer. Post-Install Setup : at this step we use a script we pull from github to install extra software we think would appeal to average computer users. Things like DVD playback, sound, webcams, and USB ports are also tested at this stage. Quality Assurance : Someone else takes over at this stage and goes through a separate checklist to ensure the computer is in good working order. Sales Preparation : This is the final stage where the computer will be priced, a barcode and information sticker attached to the computer, and the computer information goes into our Point-Of-Sale (POS) system. This is a very generalized list of steps, the actual process is a fair bit longer, and we sometimes run into issues… The Lenovo ThinkStation C20 is one of those times where we ran into a minor issue and needed to reconsider which version of Linux we were installing on the machine.\nThe Lenovo ThinkStation C20 The Lenovo ThinkStation C20 is a very old machine by today’s standards – it appears to have come out Q4 of 2010. The machine we received had a single XEON E5620 CPU (4 cores, 8 threads) running at 2.4GHz. One of the things that makes this workstation interesting is there is a spot for a second XEON CPU on the motherboard (along with another 3 RAM slots – 3 for each CPU). I’m not sure if the machine had the standard install of 4GB of DDR3 and we upgraded that to 8GB, or the person who donated the machine upgraded it to 8GB. Either way the machine currently has a single 8GB stick installed. The graphics card is the original NVidia Quadro 2000 card that would have come with this workstation. The Quadro 2000 ended up being a pain-point for building the machine, but more on this later.\nNormally the ThinkStation C20 would have come with a 300GB 10,000 RPM hard drive. We always pull drives out of desktops to be batch wiped with other drives. Finding good 10,000 RPM hard drives is difficult these days. And while most of the world has moved on to solid state drives, we don’t see a lot of SSDs at Computer Recycling. We do see a lot of 500GB hard drives, so that’s what we put in the C20. Sadly, we chose a WD Blue drive. This wouldn’t have been my first choice, a WD black drive would have been a better choice, but the blue drive tested fine and was what ended up being put in.\nIt’s possible the Computer Recycling project might have another XEON E5620 CPU lying around, but even if we found one, we don’t have the heat sink needed to cool the extra CPU. So for now, we’re just using the single XEON processor.\nInitial Xubuntu Install One of our volunteers initially installed Xubuntu 22.04 on the C20. Xubuntu appeared to work great, but one of the benchmarks we run (Xonotic game), was really low (39.54 FPS for high detail at 1024×768). Checking the driver I noticed that they were using the open source driver, rather than the available (Nvidia-390) proprietary driver. Our new checklists mention checking for proprietary drivers using the drivers program in Xubuntu/Linux Mint, but the checklist this volunteer was working from was older and didn’t mention this step.\nHowever, even if the volunteer followed the newer checklist, they still would have failed to install the driver. It turns out that the proprietary driver fails to install in Xubuntu 22.04 (and Linux Mint with a newer kernel). After a bit of digging I discovered that the NVidia-390 driver needs an old kernel. The kernel in Xubuntu 22.04 is too new to support the old proprietary NVidia driver.\nInstalling Linux Mint While I fully expect whomever buys this machine won’t use it as a gaming machine (it’s 2010 remember), squeezing a few extra FPS out would be nice. Knowing that Linux Mint XFCE (21.3 – Virginia) uses an older kernel I decided to try installing Linux Mint to see if the proprietary NVidia driver would work. Yes, it did. And it turned out that it was significantly better, 172.20 FPS (vs the 39.54 FPS using the open source driver).\nFig. 1 - Linux Mint\nBefore people go slagging the open source driver developers, the bad performance of this old NVidia card is not their fault. Traditionally, NVidia hasn’t been very helpful to the open source community (thus the infamous Linus Torvalds cursing NVidia video).\nWhile NVidia has a page full of open source projects, I am sure they’re not interested in spending the time to update ancient drivers like this to work with modern versions of Linux. It’s a bit sad, as a machine like this C20 could still be a very useful workstation, especially with the max 192GB of RAM, and an SSD.\nAfter installing the NVidia driver I also ran Timeshift, and set up a restore point for the computer. I figured I would try updating the kernel on Linux Mint, because they make it dead simple to do so. Sadly this resulted in the machine not booting to the desktop, as it had done with Xubuntu. This wasn’t an issue because I was able to just switch to a virtual terminal (CTRL + ALT + F1), login, and run:\ntimeshift --restore Timeshift then displays the restore points you’ve set up and lets you choose a point to restore to. I restored back to the kernel the proprietary driver worked on, and voila, the machine was ready to go, back at the desktop. This also confirmed that the issue is compiling the source against a newer kernel.\nFig. 2 - Timeshift\nConsidered changing video cards I also considered changing the video card in the C20 to an ASUS branded AMD HD7750, which scores about 47% better on synthetic tests than the Quadro 2000, but sadly the height of that card is about 10 mm too high to fit in the case properly. The other video cards we have that don’t have a PCIe power connector are all much older, so the Quadro 2000 ended up being the best fit. Something like a low profile GTX 1030 might be the cheapest price/performance card that would actually fit in this machine, but then again we’re dealing with NVidia.\nStill More Work To Do There’s still a bit more work to do on this system. The lid has a lot of very deep scratches on it, so I plan to take it out an spray paint it matte black to get it looking similar to the rest of the system. It’s a neat machine with potential. Once done we’ll likely sell it for around $50 CDN, but for the moment it’s back in our to be refurbished area until we can clean it up a bit more.",
    "description": "Note: This is an older post, reposted from the old web site. The project has since mostly switched to Linux Mint XFCE versions 21.3 (Virginia) and 22.1 (Xia). We still have Xubuntu 24.04.2 on our PXE server, but only install it on request. Our checklist has evolved and we’ve separated some steps into other checklists. See my github repositories for more info.\nWorkstation class hardware at a deeply discounted price Every now and then the Computer Recycling Project at The Working Centre gets a really interesting piece of hardware donated. As a not-for-profit project, most of our equipment is aimed at people who are lower income. This generally translates into lower prices, even for some equipment others would list for a lot more. But that doesn’t mean the project just wipes the machines, installs Linux, and dumps the equipment on a sales shelf… often equipment requires a little, or a lot more work.",
    "tags": [
      "Computer Recycling",
      "Computer Refurbishing",
      "Linux Mint",
      "Xubuntu",
      "Hardware",
      "Lenovo"
    ],
    "title": "Linux on the Lenovo Thinkstation C20 (MT-M 4265-93u)",
    "uri": "/posts/linux_on_the_lenovo_thinkstation_c20_mt_m_4265_93u/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Note: While I tried using Linux Mint XFCE at home for awhile, I still found Xubuntu 24.04.2 works best for my use cases. There are some filesystem differences, and while I was adverse to snaps because of control issues, I’m finding they have some advantages over flatpak that I like. This is a repost from the old website.\nXubuntu Linux version 24.04 is out Version 24.04 of Xubuntu Linux is now out! Xubuntu Linux has been a staple of the Computer Recycling Project @ The Working Centre since 2010. With the project switching mostly to Linux, it’s now more important than ever that we’re up to date on trends, and new developments that affect the project. This new version of Xubuntu has a number of nice improvements, but in my testing on several different machines I’ve run into a number of issues as well.\nNote: We’ve since switched to Linux Mint XFCE at the project, but we continue to offer Xubuntu to anyone who wants it.\nThe good stuff The biggest, baddest (in the good sense), improvement to Xubuntu Linux is the desperately needed improvement to the “Software Center” application. Gone is the slow-as-molasses GNOME SOFTWARE application. It’s been replaced by the “App Center,” an application/program installer made with flutter (a user interface development kit developed by Google and the community). The new App Center looks much better, loads much faster, and it’s a lot more intuitive. It no longer takes minutes for a simple app search.\nThe most obvious change to Xubuntu is the vibrant new green wallpaper and theme. The theme is still Greybird, but the menu icons are a lot more vibrant, and the overall look is just a cleaner. I love the new theme and wallpaper.\nFig 1. Software - the software installation app is much faster\nThunar, the file manager, now supports the long-awaited split pane feature. Windows + F launches the Thunar file manager in Xubuntu, and with it opened, and in focus, if you press F3 you’ll split the panes, making it easy to navigate and copy files between directories.\nXubuntu 24.04 also includes firmware-updater, a nice flutter application that checks for firmware updates for various devices (for example, NVMe/SSD/HDD, UEFI/BIOS) in your PC. and lets you update those devices to the latest firmware. There was a firmware update program in 22.04, but when I tried it, it only indicated updates were available for devices. The “software” program in Xubuntu 22.04 was also capable of downloading BIOS updates, which would get implemented on reboot. This new flutter firmware-updater is really well done, at least in our limited testing.\nThe bad stuff The new installer seems to have issues loading up, even on “stock” machines. I tried the installer on a stock Acer Aspire AT3-710-EB62 (6th gen i7-6700) paired with a Dell 27″ monitor and the display was “glitched” and wouldn’t map correctly. The system was previously working perfectly with Xubuntu 22.04. My first thought was issues with the 27″ display, but this particular Aspire has a Radeon R9 360 2GB video card, which shouldn’t have any issues with the 1080p 27″ display, at least not for normal/basic use. I wasn’t able to click on things, and the system just locked up. Shortly after I tested the same USB-based Xubuntu 24.04 install on a stock Dell machine with lesser specs (4th gen), and it worked just fine. The display issues only seem to happen with some machines.\nThe App Center is a huge improvement, and while it’s still in the list when you type “software” in the whisker menu, I feel like renaming it the App Center is a not a good move. This is more a personal annoyance. The Software Centre was previously renamed Software, and now it’s being renamed App Center. Changing the name of software leads to confusion across versions and makes it harder to document, and harder for less experienced users trying to follow documentation. I tend to think of “Apps” as lightweight/limited phone programs, rather than full-fledged software. One of the complaints we’ve heard at the project is the fact that things don’t work because someone is looking at old documentation where something has changed. A minor grievance, but I think a valid one.\nI was also a bit disappointed to see that the new wallpaper only extended to the default green wallpaper. While I love the change, and the bright new icons, it seems to be the only new wallpaper included with 24.04. Again, this is something that’s very minor, but I’ve come to look forward to seeing new wallpaper with each release. It would be nice to see new themes with each release as well, but as someone who was involved with a Linux distribution many years ago (2001-2004) I realize how hard it can be.\nAnother issue I ran into was Window snapping. It appears to be gone in Xubuntu 24.04. In version 22.04 you could grab a window, drag it to the right or left side of the screen, and it would snap against the right or left side, and open a 1/2 page view of that window. This made it easy to see a couple of pages side by side. That feature appears to be disabled in the default install of Xubuntu 24.04.\nFlutter installer just doesn’t work in a live PXE install Update: This issue was fixed in Xubuntu 24.04.1 and still appears to be okay in 24.04.2\nAt The Working Centre’s Computer Recycling Project we deploy Linux using a network boot PXE (Pre-eXecution Environment) server. This is a fancy way of saying rather than setting a computer to boot from a USB key and installing from the key, we set the computer to boot from the network card, which connects to a server, that tells it to get instructions/downloads from another server. I set up a couple of different ways to boot the Xubuntu 24.04 Live image on our PXE server. Both methods load up the image into RAM, but when you click the installer icon on the desktop, the flutter installer window opens up a window that says “Preparing Xubuntu”, but it never gets past the Preparing Xubuntu window. Eventually, a “System Problem detected” window pops up, but the preparing Xubuntu flutter window never disappears, and clicking report the crash appears not to work.\nFig 2. The flutter installer used to hang via PXE install\nSnaps Of course I haven’t tackled the 6000 kg elephant in the room, snap packages. There’s a lot of hate for snap packages. Some of the reasons people cite for disliking snaps are:\nSpeed : although some of this has been corrected with recent updates, applications still load slower than their .deb counterparts. The snap store is controlled by Canonical. Debian packages are mirrored, so if you have an issue with a mirror, you can change mirrors, no so with the snap store. Canonical started replacing software like Firefox, Chromium, and Steam with snap versions, something they initially said they wouldn’t do. How do you trust them not to behave badly later on? Connectivity speed : this is something I added because we found issues trying to install snap packages during the release of 24.04. Again, having more mirrors might help with this problem. Security : while Canonical did catch a crypto miner that a company placed in it’s software, the initial malware scanner missed the miner. Not being able to audit the code, and having auto-updates, could pose a problem. Canonical’s own advice is to “only install snaps from sources you trust.” So why force snaps on people, if you don’t have 100% confidence. Default to Debian packages and let people choose snaps. Debian packages fail after snap versions appear : some have complained that the Debian packages they used in previous versions of *buntu don’t work in new versions, and have been replaced with snap packages. While we haven’t directly experienced this, we’ve found on some machines the (22.04) Debian package of VLC crashed while the snap package worked (loading a DVD). Space : snap packages take up more space. I still feel Debian packages are the best way to go. That said the Computer Recycling Project did use to install a few snaps:\nANTSY Alien Attack : a pico8 SHMUP game made by the developer of Ubuntu Mate Fre:ac : a CD ripping program with nice auto lookup features Microsoft Office web apps – to connect to MS Office online We stopped installing any snaps recently. While we trusted the sources for those snaps, we just don’t feel we should add to the growing snap installs on machines.\nComputer Recycling switched, but I still have not This was an older post, but I’ve removed the previous conclusion because there have been a lot of improvements since Xubuntu 24.04 was first released. As I mentioned earlier in this article, while I use both Xubuntu 24.04.2 and Linux Mint XFCE 22.1 at work, my preference at home is to still use Xubuntu 24.04.2.\nHandbrake, which I use a lot to compress my media, has better behaviour when queueing a lot of files. While re-developing this web site I found I preferred to install hugo via snap. I could have used homebrew, and I did on a Linux Mint machine, only to find it did a lot of things I didn’t like (creating a user directory in /home for the application)\nFinally, I also found I had less issues with Steam on Xubuntu (using the Debian package straight from Valve). For the foreseeable future I’ll continue to update Xubuntu on our PXE network server alongside Linux Mint XFCE, so if you’re ever in our neighbourhood and would like to install either of these great systems feel free to drop in.",
    "description": "Note: While I tried using Linux Mint XFCE at home for awhile, I still found Xubuntu 24.04.2 works best for my use cases. There are some filesystem differences, and while I was adverse to snaps because of control issues, I’m finding they have some advantages over flatpak that I like. This is a repost from the old website.\nXubuntu Linux version 24.04 is out Version 24.04 of Xubuntu Linux is now out! Xubuntu Linux has been a staple of the Computer Recycling Project @ The Working Centre since 2010. With the project switching mostly to Linux, it’s now more important than ever that we’re up to date on trends, and new developments that affect the project. This new version of Xubuntu has a number of nice improvements, but in my testing on several different machines I’ve run into a number of issues as well.",
    "tags": [
      "Linux",
      "Xubuntu",
      "Hardware",
      "Computer Refurbishing",
      "Shell Scripting"
    ],
    "title": "Xubuntu 24.04 bugs so far - May 3 2024",
    "uri": "/posts/xubuntu_2404_bugs_so_far_may_3_2024/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Migrating the KODI entertainment system On May 5th I mentioned that we’re Running out of space on our media center. In the comments of that post I followed up outlining a plan to buy another 8TB drive (for a total of 3 x 8TB drives) in order to do a RAID Z1 (for 16TB of space). But in order to do that I would need to reformat the drives, which means I also needed a plan to back up our media center data. I hinted at that solution in the comments too: 4 x 3TB drives in a RAID Z1 – which would give me 9TB of space (1 x 3TB is the spare), just enough to back up all the data.\nAt first I was thinking of putting the drives in my old Antec Three Hundred Two Atermiter X79 XEON build (the machine we use for ripping media), but that machine is in heavy use, doubling as a media center in another room, on top of it’s ripping duties. I’ve been watching quite a few NAS build videos lately, and noticed in the comments someone mentioned the Dell PowerEdge T110 II, a Dell workstation with room for 4 x 3 .5″ drives. The Working Centre’s Computer Recycling Project just happened to have a T110 II with a Pentium G620 processor. The project has been running a sale on desktop machines and workstations. The project has a base price for 1st gen Core i3’s at $50, the half-off sale means the 1st gen i3’s are going for $25. This G620 is one step down from the i3’s, so I got it for $20. The machine came with 8GB DDR3 (I haven’t checked to see if it’s ECC or not) and a 1TB drive, which I donated back to the project.\nDrives, this could be a problem… My original plan was to use 2 x 3TB Seagate Constellation drives and 2 x 3TB Seagate Barracuda drives, but one of my 3TB Barracuda drives appears to be completely dead. As an aside, I’ve been wiping lots of drives at the project lately and it’s been a 50/50 split between WD/Seagate drive failures so far. I have a 3TB WD Red, but I’m not sure mixing and matching all these various drives is going to work. My fingers are crossed that what really matters is they’re close in size to each other.\nFig 1. 3D printed slot mounting bracket for the boot SSD\nI also wanted to have a solid state OS/boot drive. The system is pokey enough that it would really benefit from an SSD. My initial plan was to 3D print a riser card that I could attach on the back of the T110 II where the PCI slots are. I had to rethink this because of the large plastic baffle that covers the processor and RAM. The baffle prevents the short SATA power cable from routing nicely to the slots. I’ll use this 3D printed riser in a different system, it’s pretty handy. At the moment I’m printing a 5 1/4 tray with mounting holes for both 2.5 and 3.5 inch drives.\nThis also brings up the fact that I needed to disconnect the DVD drive in order to accommodate the SSD, but I never planned on using the DVD drive anyway, so it’s not a big deal.\nOperating system The plan thus far is to put TrueNAS Scale on the system. I have Scale on a machine at work and so far it’s been very reliable. I still need to wait on the SSD mount and dig up my WD Red to test and see if this is going to work as expected or whether I need to pick up another Constellation or two. Sadly, The Computer Recycling Project doesn’t have a lot of large drives, and most of the big drives the project has (2TB) have failed. I have a few other sources I can pick drives up from, and I’ll provide more details if it ends up I have to buy other drives.\nFig 2. 3TB Seagate Hard Drives\nNot the ultimate plan, this is just an intermediate step Neither the media center upgrade, nor this side backup project are my ultimate storage plan. These are small steps towards a larger capacity NAS. We need a NAS for our media center, but we also need storage for future YouTube videos, and some storage for synchronizing our cell phones (neither of us rely on Google Drive).",
    "description": "Migrating the KODI entertainment system On May 5th I mentioned that we’re Running out of space on our media center. In the comments of that post I followed up outlining a plan to buy another 8TB drive (for a total of 3 x 8TB drives) in order to do a RAID Z1 (for 16TB of space). But in order to do that I would need to reformat the drives, which means I also needed a plan to back up our media center data. I hinted at that solution in the comments too: 4 x 3TB drives in a RAID Z1 – which would give me 9TB of space (1 x 3TB is the spare), just enough to back up all the data.",
    "tags": [
      "TrueNAS",
      "NAS",
      "Network Attached Storage",
      "Storage",
      "Hardware",
      "Linux",
      "Media",
      "DVD",
      "Blu-Ray",
      "Networking"
    ],
    "title": "Dell PowerEdge T110 II Network Attached Storage (NAS) build",
    "uri": "/posts/dell_poweredge_t110_ii_nas/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Classic Gaming",
    "uri": "/tags/classic-gaming/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: DOS",
    "uri": "/tags/dos/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Prince of Persia",
    "uri": "/tags/prince-of-persia/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Prince of Persia - a classic game for DOS When I first ran Prince of Persia on PC-DOS I remember thinking, “finally, a DOS game that rivals the fun I had on Commodore 64 games.” I was never very good at the game (and that continues today), but it’s a classic game.\nThe original DOS version has a port for Linux which you can find on github here:\n(https://github.com/NagyD/SDLPoP?tab=readme-ov-file)\nThe simplest method to install SDLPoP on Ubuntu/Xubuntu Linux If you’re on Xubuntu, or another Ubuntu-variant, there is a snap for the game (called sdlpop). To install the snap simply open a terminal and type:\nsudo snap install sdlpop Snap may take a minute to install all the necessary files, but once it does you can find SDLpop in the Xubuntu whisker menu. But I recommend launching it from the terminal, as you can launch it with options. If you type:\nsdlpop full SDLpop will launch in full screen mode.\nFig 1. Playing SDLPoP on Xubuntu Linux\nSDLpop is more than a clone of Prince of Persia, it’s been expanded on to include more options than the DOS version had. If you compile the code yourself you can also modify SDLPoP.ini. While the file exists in the snap version of SDLpop it can’t be modified because the snap format prevents this (for security reasons).\nI couldn’t find SDLpop in flathub, so it doesn’t appear to be available as a flatpak (which means it isn’t as simple install for Linux Mint or Debian users).\nCompiling SDLPoP If you want a bit more control over SDLPoP there’s a configuration file SDLPoP.ini that can be modified in the compiled version. Sadly this file cannot be modified in the snap version of SDLPoP (for security reasons snap won’t let you modify snapped files — in general). I found compiling SDLPoP was not that difficult.\nFirst clone the git repository (make sure you have git installed of course – sudo apt install git -y):\ngit clone https://github.com/NagyD/SDLPoP SDLPoP needs a the libsdl2-image-dev library before you can compile SDLPoP. I also always recommend installing build-essential as it covers building quite a bit of software.\nsudo apt install libsdl2-image-dev build-essential -y With these installed change into the cloned repository directory and then the src directory, then make and sudo make install. (If you later want to uninstall you can run sudo make uninstall in the same directory).\ncd SDLPoP/src/ make sudo make install After you run SDLPoP you should be able to find SDLPoP by clicking on the Xubuntu whisker menu in the top left and typing sdl.\nWhen SDLPoP is first run you’ll notice it defaults to a pretty small size 640×400 (16:10 aspect ratio). There are a couple of things you can do to make it larger. The first thing, which works both in the snap and compiled version is to press ESC to bring up the SDLPoP menu, use the keyboard arrow keys to navigate to Visuals, then turn on the full screen mode. This will put SDLPoP in full screen mode.\nFig 2. SDLPoP options screen\nThe second thing you can do, which only works in the compiled version, is to modify the SDLPoP.ini file. Unlike a lot of software I’ve compiled, SDLPoP doesn’t move itself into /usr/share, or a system folder. When you compile SDLPoP it compiles in place, meaning that the binary (prince) is made in the SDLPoP directory you pulled from github. For example, on my system it went to:\n/home/chaslinux/Code/SDLPoP I like to put all my github projects in a directory off my home directory called Code (/home/chaslinux/Code). If you just clone the repository into your home directory it would be something like /home/chaslinux/SDLPoP.\nYou can just change into the SDLPoP directory and modify the SDLPoP.ini file:\ncd SDLPoP mousepad SDLPoP.ini On Linux Mint replace mousepad (above) with xed, the editor used in Linux Mint Cinnamon and XFCE. Because the file is stored within your own home folder you won’t need elevated sudo privileges to edit the configuration file. Mousepad is the default text editor in Xubuntu. If you’re using another distribution like Ubuntu you might have to use another editor like xed, gedit, vi, or nano.\nUnder the General section of the file modify the lines:\npop_window_width = default pop_window_height = default You’ll want to use something that’s one of the 16:10 aspect ratio resolutions to make sure SDLPoP scales correctly (looks right). I’m on a fairly large screen so I chose 1680 x 1050.\npop_window_width = 1680 pop_window_height = 1050 Fig 3. Running SDLPoP in a window at 1680x1050\nThere are a number of other options that can be changed in this SDLPoP.ini file. Some of those options can also be passed on the command line if you launch SDLPoP in a terminal. The command to run SDLPoP is prince (as in Prince of Persia), but the executable file is located outside of the normal PATH the BASH shell understands. So if you just try to run prince from your home directory you might get a:\nprince: command not found To make prince findable to your BASH shell you’ll have to add the path to the prince binary to your .bashrc file. As I mentioned earlier, in my case the path is /home/chaslinux/Code/SDLPoP. The .bashrc file is located in your home directory:\ncd ~ nano .bashrc At the end of my .bashrc I added the line:\nPATH=$PATH:/home/chaslinux/Code/SDLPoP Note the $ after the second PATH, and the colon before the path to the prince executable. In the example above replace chaslinux with your username. You don’t need to put the executable at the end of the path as everything in the SDLPoP directory will be added to the BASH PATH. Now close the initial terminal and open a new terminal, prince should now be executable from your home folder. Typing:\nprince full Launches SDLPoP in full screen mode.\nI hope this helps someone, and that more people learn about some of the fun old school games we used to play, that are also available on Linux.",
    "description": "Prince of Persia - a classic game for DOS When I first ran Prince of Persia on PC-DOS I remember thinking, “finally, a DOS game that rivals the fun I had on Commodore 64 games.” I was never very good at the game (and that continues today), but it’s a classic game.\nThe original DOS version has a port for Linux which you can find on github here:\n(https://github.com/NagyD/SDLPoP?tab=readme-ov-file)\nThe simplest method to install SDLPoP on Ubuntu/Xubuntu Linux If you’re on Xubuntu, or another Ubuntu-variant, there is a snap for the game (called sdlpop). To install the snap simply open a terminal and type:",
    "tags": [
      "Gaming",
      "Linux",
      "SDLPoP",
      "Prince of Persia",
      "DOS",
      "Retro",
      "Retro Gaming",
      "Classic Gaming"
    ],
    "title": "Prince of Persia for Linux",
    "uri": "/posts/prince_of_persia_for_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Retro",
    "uri": "/tags/retro/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Retro Gaming",
    "uri": "/tags/retro-gaming/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: SDLPoP",
    "uri": "/tags/sdlpop/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Software",
    "uri": "/categories/software/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: C64",
    "uri": "/tags/c64/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Commodore 64",
    "uri": "/tags/commodore-64/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Freedroid",
    "uri": "/tags/freedroid/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Paradroid, has a version for Linux Growing up in the Commodore 64 era, I’m particularly fond of the games of that age. Games in that era tended to be simpler, but sometimes within that simplicity were some really neat concepts. Paradroid was one of those games that was particularly unique and interesting.\nThere’s a really good look-back at Paradroid on the LemonTube64 Youtube channel here:\n(https://youtu.be/kkEBccMEhXs)\nFreedroid “classic” is a port of the game to Linux. The website for Freedroid classic might be a bit confusing when you first arrive because the same developers also worked on an isometric 3D-like game they called FreedroidRPG. The web site for both is:\n(https://www.freedroid.org)\nCurrently there is no mention of Freedroid classic on the landing page for FreedroidRPG, but if you go to the Download page, it’s mentioned about half-way down.\nInstallation of freedroid classic is easy To install Freedroid classic on Xubuntu Linux simply open a terminal (Windows + T key) and type:\nsudo apt update sudo apt install freedroid If you then open the Xubuntu whisker menu in the top left and type freedroid you should find the game… but if you run the game from the terminal you can also add “switches” to do things like make the window larger, launch in full screen mode, launch with no sound, launch with debugging turned on, etc.\nGameplay In Freedroid classic you start as a 001 droid, the lowest of the low in the droid pool. In the game you’re on a massive ship that’s full of droids that are more powerful than your starting droid. To win the game you have to destroy all the droids on all levels. Sounds simple enough, but the game has a few twists.\nAs a 001 droid you’re relatively weak. It takes several shots to destroy robots with larger numbers. But don’t fret, you possess an “influence device” (a helmet) that lets you try to take over other droids if you hold down the fire key when you crash into them. Be aware that droids who crash into you weaken your shields. If too many droids crash into you, or you’re fired upon by a sufficiently powerful droid, it’s game over.\nWhen you crash into another droid with the influence device activated a mini-game opens up. At the start of the mini game you have a few seconds to pick a side you want to be on (various colours, generally one light, one darker). Depending on the side there are routed wires that go to the center. The idea is to pick the correct set of wires so that your colour is dominant.\nFig 1. Freedroid - 320 robot trying to take over a 420\nThings that affect the mini (wire) game:\nAs a low level robot you have fewer wires you can use Some of the wires fork, both to your advantage and disadvantage Time counts down quickly as you choose which wires to take Once you pick a wire, you cannot unpick it The first couple of times you try the game things are a bit confusing, in part because you first have to pick a side, but then as you get used to how the mini-game works. At the end of the countdown if more wires are your colour, you win and take over the robot. If more wires are in the opposing robots colour, you lose. If the center turns black, it’s a stalemate and you both go again.\nIn addition to other droids there are consoles you can check out, shield-restoring squares (at the cost of game score), and transfer areas that you can use to go to another level. Be careful not to jump to the highest levels right away. The higher the droid number, the more likely they are to fire, and the stronger they tend to be (both shield and firepower wise).\nFig 2. Freedroid - taking the elevator\nFreedroid is an awesome port of this wonderful game. If you enjoy old school games, or just have old hardware and want to try something different, give Freedroid Classic a try.\nBe the best robot you can As a 001 your weapon sucks, but as you take over more powerful robots your weapon’s power gets stronger, but the most fun lies in trying to take over stronger robots. You can choose to try to shoot more powerful robots, but they might get you before you get them. And yes, I managed to take over the 420!\nFig 3. Freedroid - I took over the 420",
    "description": "Paradroid, has a version for Linux Growing up in the Commodore 64 era, I’m particularly fond of the games of that age. Games in that era tended to be simpler, but sometimes within that simplicity were some really neat concepts. Paradroid was one of those games that was particularly unique and interesting.\nThere’s a really good look-back at Paradroid on the LemonTube64 Youtube channel here:\n(https://youtu.be/kkEBccMEhXs)\nFreedroid “classic” is a port of the game to Linux. The website for Freedroid classic might be a bit confusing when you first arrive because the same developers also worked on an isometric 3D-like game they called FreedroidRPG. The web site for both is:",
    "tags": [
      "Gaming",
      "Linux",
      "Freedroid",
      "Paradroid",
      "C64",
      "Commodore 64",
      "Retro",
      "Retro Gaming",
      "Classic Gaming"
    ],
    "title": "Freedroid - Paradroid (C64) for Linux",
    "uri": "/posts/freedroid_paradroid_for_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Paradroid",
    "uri": "/tags/paradroid/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "On systemd-based distributions it’s possible to boot to the BIOS from Linux Have you ever found yourself working on a computer that’s just so blindingly fast that you just cannot mash the key you need to get into the BIOS fast enough? It might be possible to reboot from your Linux system into the BIOS of your computer.\nNot all systems support this feature. On the one system we tested this on which didn’t boot to the BIOS the error message mentioned something about the EFI partition. But I was able to successfully run the command on a couple of systems, a 4th gen and 8th gen system.\nThe command to run is:\nsudo systemctl reboot --firmware-setup Fig. 1 - Booting to the BIOS via command line on Linux Mint 22.1\nBe sure to properly close any open documents before running this command as it will reboot the computer and then force the “firmware”/BIOS to start up.",
    "description": "On systemd-based distributions it’s possible to boot to the BIOS from Linux Have you ever found yourself working on a computer that’s just so blindingly fast that you just cannot mash the key you need to get into the BIOS fast enough? It might be possible to reboot from your Linux system into the BIOS of your computer.\nNot all systems support this feature. On the one system we tested this on which didn’t boot to the BIOS the error message mentioned something about the EFI partition. But I was able to successfully run the command on a couple of systems, a 4th gen and 8th gen system.",
    "tags": [],
    "title": "Reboot to the BIOS from Linux",
    "uri": "/posts/reboot_to_the_bios_from_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "The problem is power management (workaround) You’ve installed Xubuntu 22.04 on your laptop and things are going smoothly… Then you close the lid on your laptop and discover when you open it back up again that when you move the mouse it moves, but you cannot right or left click for some reason? The issue appears to be with power management.\nThe work around we found that appears to fix this is to edit the file:\nsudo vi /etc/UPower/UPower.conf In this file there’s a line that says:\nIgnoreLid=false Change this to:\nIgnoreLid=true Make sure you spell true with a small “t,” if you use a capital for True, it won’t be recognized. Try restarting and now you should be able to open and close the lid without the mouse locking the left and right click.",
    "description": "The problem is power management (workaround) You’ve installed Xubuntu 22.04 on your laptop and things are going smoothly… Then you close the lid on your laptop and discover when you open it back up again that when you move the mouse it moves, but you cannot right or left click for some reason? The issue appears to be with power management.\nThe work around we found that appears to fix this is to edit the file:",
    "tags": [
      "Hardware",
      "Linux",
      "Computer Refurbishing",
      "Xubuntu"
    ],
    "title": "Cannot click after laptop lid closed and re-opened - Xubuntu Linux",
    "uri": "/posts/cannot_click_after_laptop_lid_closed_and_reopened_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Switching printers at home Other than running out of toner, there was nothing wrong with the HP Laserjet P1102w printer we have at home. The printer printed cleanly, was compact, and was connected to our wireless network, so any machine on our network could print to it. In fact, I was planning on buying more toner this evening after we did our usual scouring of thrift shops. I thought there was a small chance I might find the right HP 85A toner at one of the stores we planned to go to. I did find some other toner at one of the thrift shops, and the $5.95 price tag wasn’t bad, but it was for a different model in the same line of printers. But this was actually after spotting an even better deal, an HP Laserjet 1320 duplex printer for a whopping $10.95.\nI’m familiar with the HP Laserjet 1320 as this is the printer we use at several places at work. I’m normally not a fan of HP printers, despite the fact our previous printer was also an HP Laserjet. HP printers tend to be a pain to configure in Linux, and they do nasty things with toner on newer models. But, being very familiar with this printer, I knew it would be a great printer if it worked.\nTesting the HP Laserjet 1320 The printer was pretty dirty on top. I opened the top part to check for toner, it was there. I wasn’t about to buy the printer without checking for issues like streaking, or empty toner. The power cable looked like it had been through a rain storm, but the printer had both it and a USB cabled plugged into the back of it. I turned off the power switch on the right-hand side, plugged the printer into the test station at the thrift shop, then powered the printer on. After the printer ran through it’s brief startup routine I held the green button on the top to start a test print. To my surprise/delight, a crisp looking test page printed, without any toner spots or issue.\nPerks / issues The big draw of the HP Laserjet 1320, at least for me, is it’s ability to do duplex (double-sided) printing. The printer is automatically recognized by Xubuntu, and print quality is decent. While the printer tray normally holds around 120 sheets, there’s an optional tray available to hold up to 250 sheets (HP P2015 sheet feeder with tray). The extra tray ads about 3 inches to the printer height, but if you print a lot, it might be a good idea. In our family use case, 120 pages is more than enough.\nFig 1. HP LaserJet 1320 laser printer\nWhile new HP-branded (HP 49A) toner for this printer is expensive: $176.99 CA, it’s capable of a yield of 2,500 pages. Lots of off-branded toners exist at reasonable prices ($29 – $50) on Amazon.\nFirst steps The first step is to make sure the printer is available locally on the machine it’s connected to. In Xubuntu you can click the whisker menu in the top left (or just press the Windows key on the keyboard to open the menu) and type printers into the menu. You should see a program you can click to open up a list of locally connected printers.\nSharing the printer Sharing a printer that’s connected and working on a Xubuntu Linux system is a whole lot easier than you might expect.\nIn the web browser on the computer the printer is connected to type: (http://localhost:631)\nNext, click the Administration tab at the top of the OpenPrinting CUPS web site that opens. At this point you will be prompted to enter a username and password, this is the same as the user account you’ve set up.\nOnce on the Administration page it’s simply a matter of clicking the Advanced \u003e Share Printers connected to this system and clicking the Change Settings button below.\nFig 2. OpenPrinting CUPS administration screen\nThat’s it! Provided the printer is already working connected to your networked Xubuntu desktop, it will now be available to other computers on your network, including systems running Windows.",
    "description": "Switching printers at home Other than running out of toner, there was nothing wrong with the HP Laserjet P1102w printer we have at home. The printer printed cleanly, was compact, and was connected to our wireless network, so any machine on our network could print to it. In fact, I was planning on buying more toner this evening after we did our usual scouring of thrift shops. I thought there was a small chance I might find the right HP 85A toner at one of the stores we planned to go to. I did find some other toner at one of the thrift shops, and the $5.95 price tag wasn’t bad, but it was for a different model in the same line of printers. But this was actually after spotting an even better deal, an HP Laserjet 1320 duplex printer for a whopping $10.95.",
    "tags": [
      "Computer Refurbishing",
      "Hardware",
      "Printing",
      "Networking",
      "Linux",
      "Xubuntu",
      "HP",
      "Laser Printer"
    ],
    "title": "Adding a laser printer as a shared network printer in Xubuntu Linux",
    "uri": "/posts/adding_a_laser_printer_as_a_shared_network_printer_in_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: HP",
    "uri": "/tags/hp/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Laser Printer",
    "uri": "/tags/laser-printer/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Printing",
    "uri": "/tags/printing/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "OBS is awesome! Open Broadcasting Software, also known as OBS Studio, is an awesome piece of free and open source software that lets you capture audio and video from a wide variety of sources: screen capture, webcam, audio capture from the system, from an external source, from static images, slide shows, etc.\nIt’s been awhile since I’ve used OBS to capture the desktop of one of the systems at work, an ASUS M51AC desktop with an i7-4770 CPU, 16GB of RAM, and a 256GB SSD. I installed OBS 30.0.1 and started to record a video of the desktop, using the webcam microphone for audio. After a bit of tweaking, adjusting Xubuntu’s microphone sensitivity, I managed to get audio recording correctly so audio levels did not “clip” (go into the red) in OBS.\nThinking I was done I recorded a video, only to find out later OBS had only captured a static image, and none of the adjustments I made to the desktop. At first I thought it might be due to the fact that I was recording 2k display, and also driving a second 1080p display. When I lowered the 2k display capture to 1080p it still refused to capture any of the desktop movement.\nThe solution turned out to be adding a graphics card. I was trying to capture the display using onboard video. While the M51AC’s onboard graphics is enough to drive the 2k and the 1080p displays, it’s not enough to capture the display correctly.\nWhile I’m not a big fan of NVidia cards, I find their drivers tend to crash in Xubuntu and require removing and reinstalling, I put an NVidia Quadro P1000 (4GB) card into the M51AC. After installing the card I loaded up Timeshift and created a restore point.\nIf you haven’t used Timeshift yet, it’s a simple point and click program that lets you create a system restore point. You can exclude your home directory so you’re not time shifting your entire Steam library (not backing up /home is the default behaviour).\nThe next task was to install the proprietary nvidia drivers. In Ubuntu/Xubuntu (or Linux Mint) this is pretty simple, just click on the whisker menu, type the word Drivers, open the driver program (make sure you’re connected to the Internet first or the driver program won’t be able to query the Internet to see what drivers are available). Install the “Proprietary, Tested” driver.\nReboot for the new graphics driver to take effect.\nAfter installing the driver OBS Studio correctly recorded the 2k desktop.\nIn the case where the driver borks things, timeshift has a command-line version (that gets installed with timeshift) where you can timeshift the computer back to the open source driver.",
    "description": "OBS is awesome! Open Broadcasting Software, also known as OBS Studio, is an awesome piece of free and open source software that lets you capture audio and video from a wide variety of sources: screen capture, webcam, audio capture from the system, from an external source, from static images, slide shows, etc.\nIt’s been awhile since I’ve used OBS to capture the desktop of one of the systems at work, an ASUS M51AC desktop with an i7-4770 CPU, 16GB of RAM, and a 256GB SSD. I installed OBS 30.0.1 and started to record a video of the desktop, using the webcam microphone for audio. After a bit of tweaking, adjusting Xubuntu’s microphone sensitivity, I managed to get audio recording correctly so audio levels did not “clip” (go into the red) in OBS.",
    "tags": [
      "Hardware",
      "Xubuntu",
      "Linux Mint",
      "NVidia",
      "OBS",
      "Recording",
      "Media"
    ],
    "title": "[Fix] OBS Studio records static desktop image, no movement",
    "uri": "/posts/obs_studio_records_static_desktop_image_no_movement/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: NVidia",
    "uri": "/tags/nvidia/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: OBS",
    "uri": "/tags/obs/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Recording",
    "uri": "/tags/recording/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Communication",
    "uri": "/categories/communication/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Great, and a pain Discord is one of those programs I love to hate. I like Discord because it’s a good way for people to connect with me about Computer Recycling, and I find it really handy for connecting with people about Game Development and Game Jams. But the process for updating Discord on Linux isn’t good. Normally, I update most software on my system by opening a terminal (Windows Key + T) and typing:\nsudo apt update \u0026\u0026 sudo apt upgrade -y This is really two commands: sudo apt update, which updates information about what updates are available from online sources, and sudo apt upgrade, which does the actually upgrading. The -y at the end is just to automate the process of pressing Y to say “yes, I want to upgrade.” The \u0026\u0026 in the middle processes the second command after the first, without needing a separate command/line to do it.\nDiscord doesn’t do this. Whenever Discord “finds” an update it prompts the user to download the new .deb package, but it doesn’t do any updating on its own. On top of this, if you double click the Discord .deb package to open it with the Software Centre, it won’t update it.\nTo “upgrade” Discord, I first remove it (which doesn’t remove the settings), then I add it again from the newly updated package. From the terminal:\nsudo apt remove discord -y cd ~/Downloads sudo dpkg -i discord-0.0.33.deb Of course, discord-0.0.33.deb would be replaced with whatever version was just downloaded. The next time Discord is launched, it does a bit of updating and then starts working again… until the next Discord update.\nI believe there is a more sane way of updating Discord via snaps, and snap refresh, but I’m not sure if it gets updated as often as Discord gets updated. For now, this method works, but it’s not exactly convenient.\nI would be remiss if I didn’t mention a comment left by @flyinsquirrel noting that there is an Ubuntu/Xubuntu snap for Discord:\nFWIW, the discord snap seems to check for updates and installs them itself on launch. I’m not sure the snap itself gets updated, but it does its own self-update inside its container.\nI’ve been using the snap since Darcy mentioned it, and it’s been a much better method for updating.\nDebian packages appear in the software centre, but don’t automatically update Software installed through the Software program on Xubuntu normally gets updates when updates are available in the software repositories. But if you install a “Debian package” (.deb file) either using the Software program, or by command line using ‘‘dpkg -i \u003cfilename.deb\u003e’’ the program will not get automatic updates. The reason the Debian package doesn’t get updates is because it didn’t come from the “online repositories” software installed through the Software program normally came from – it came from a download that was done manually through a web browser. Thus, in order to update any software installed through a .deb package you first have to uninstall the package using ‘‘sudo apt remove ’’ or through the graphical Software program, then install the new version using either dpkg or the Software program.",
    "description": "Great, and a pain Discord is one of those programs I love to hate. I like Discord because it’s a good way for people to connect with me about Computer Recycling, and I find it really handy for connecting with people about Game Development and Game Jams. But the process for updating Discord on Linux isn’t good. Normally, I update most software on my system by opening a terminal (Windows Key + T) and typing:",
    "tags": [
      "Gaming",
      "Linux",
      "Xubuntu"
    ],
    "title": "Updating Discord on Xubuntu Linux",
    "uri": "/posts/updating_discord_on_xubuntu_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "A dice game with a sense of humour If games like Torchlight II, Diablo III, or my favourite - Grim Dawn are your thing, Knights of Pen \u0026 Paper II will seem like a snooze-fest to you. While Knights has elements of a role playing game, it’s not an “Action” role playing game (ARPG), but more mimics the kind of play you might get from playing Dungeons and Dragons with a game master.\nUnfortunately the game is NOT multiplayer, so one of the best parts of D\u0026D is missing from Knights of Pen \u0026 Paper II, but if you’re okay with playing solo, this might be a fun title for you.\nKnights of Pen \u0026 Paper II starts out with a single overpowered player story-line, but the GameMaster (GM – computer) banishes that OP player in favour of playing with other friends (Level 1). You get to pick two character types from a selection of classes and races. Each class and race have specific strengths and weaknesses.\nIn the game I started for this review I chose:\nRich Kid/Elven/Hunter Lab Rat/Human/Mage As a Rich Kid my Elven Hunter has the added benefit that enemies drop 10% more gold. The Elven race adds +20 Energy, meaning the hunter will be able to use skills more often.\nFig 1. Knights of Pen \u0026 Paper II - The DM’s introduction\nAs a Lab Rat, the Human Mage has the benefit of an extra trinket slot. This translates into being able to carry one more item, an item that can be used to further enhance the character. Normally, characters have a total of 3 trinket slots. The Lab Rat bonus adds a 4th trinket slot. The Human race adds the perk of beginning the game with a skill point. Characters begin Knights of Pen \u0026 Paper II with no skill points, so this human race benefit means the character can choose a special attack right away.\nThere are more classes and races than the start of the game makes available. As you progress in Knights of Pen \u0026 Paper II you’ll have an opportunity to unlock other classes and races through quests and the “Magazine.” At the start of the game the “Magazine” doesn’t seem very important, but completing the objectives lined out by each magazine results in powerful items, and unlocking other cool classes, races, and DLC (Downloadable Content).\nFig 2. Knights of Pen \u0026 Paper II - My Lab Rat Human Mage\nKnights of Pen \u0026 Paper II is obviously inspired by Dungeons and Dragons, and takes a few humorous jabs at the game. The introduction with the Tarrasque is a jab at the fact that some players feel they have to play overpowered characters to enjoy the game. The “dungeon master” in the intro ends the game, eliminates several players, and starts the game back at the very beginning.\nWhile you start out with only two characters, the extra slots are there for a purpose. Once you reach a certain threshold of money you can hire other characters to fill the remaining slots. The more characters, the stronger the party is overall. Newly hired characters start at level 0 with no abilities. If the rest of your characters are level 10, and you’re fighting higher-level monsters, your level 0 character is a lot more likely to get killed during combat. I recommend going back to a lower level area, and levelling up newly added characters by hunting monsters outside of quests.\nFig 3. Knights of Pen \u0026 Paper II - Fighting 3 snakes\nVarious areas throughout the game offer quests, for gold, experience, and items. Quests often involve travelling to another area and fighting particular monsters, and/or collecting particular items. Travelling to other areas costs gold, and has a chance of a random encounter. As you move through an in-between area, you may or might not run into a random wandering monster.\nWhat do I love about Knights of Pen \u0026 Paper II? Knights of Pen \u0026 Paper II runs on computers with low-end graphics cards. Officially the Steam page recommends a 2GH+ CPU, and a Direct3D/OpenGL compatible card with at least 128MB. There is a SteamOS/Linux version, and that version seems to run fine without any adjustments on all my machines at home and the machines I use at work.\nI really love the fact that playing the game actually unlocks some downloadable content. I also like that you can buy buffs/bonuses through the main menu with in-game gold. I didn’t realize Knights of Pen \u0026 Paper II could be customized until I was well into the game.\nThe graphics in Knights of Pen \u0026 Paper II are cheesy, and nowhere near as good as some games, but they’re better than version 1 of the game.\nWhy not Knights of Pen \u0026 Paper 3? The keen-eyed will note that Knights of Pen \u0026 Paper 3 is available on Steam. Version 3 is only available for Windows, and while it might run using Proton, reviews of version 3 are very negative at this point. Judging by the reviews, version 3 appears to be lacking a lot of the features added to version 2. While it looks to have better graphics, it might be worth waiting a few more months to see if more development is on the horizon for the game. If it goes on sale for the right price I might pick it up despite the negative reviews to give my own assessment of version 3.\nI still enjoy playing version 2 of Knights of Pen \u0026 Paper. While I’m more likely to play Grim Dawn, Victor Vran, or Hero Siege, every now and then I spend a weekend or two playing Knights of Pen \u0026 Paper II again.\nKnights of Pen \u0026 Paper 2 currently costs $8.79CDN for the base game and $16.99 for the “Deluxist” version, which adds an art book, the Here Be Dragons DLC, and a soundtrack. The game has gone on sale several times, including the bundle editions.",
    "description": "A dice game with a sense of humour If games like Torchlight II, Diablo III, or my favourite - Grim Dawn are your thing, Knights of Pen \u0026 Paper II will seem like a snooze-fest to you. While Knights has elements of a role playing game, it’s not an “Action” role playing game (ARPG), but more mimics the kind of play you might get from playing Dungeons and Dragons with a game master.\nUnfortunately the game is NOT multiplayer, so one of the best parts of D\u0026D is missing from Knights of Pen \u0026 Paper II, but if you’re okay with playing solo, this might be a fun title for you.",
    "tags": [
      "Gaming",
      "Linux",
      "Knights of Pen \u0026 Paper II",
      "RPG",
      "Pixel Art"
    ],
    "title": "Knights of Pen \u0026 Paper II",
    "uri": "/posts/knights_of_pen_and_paper_ii/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Knights of Pen \u0026 Paper II",
    "uri": "/tags/knights-of-pen--paper-ii/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Pixel Art",
    "uri": "/tags/pixel-art/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: RPG",
    "uri": "/tags/rpg/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Game Development",
    "uri": "/categories/game-development/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Game Development",
    "uri": "/tags/game-development/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Gamedev",
    "uri": "/tags/gamedev/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: GameMaker",
    "uri": "/tags/gamemaker/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Previous GameMaker experience I bought version 1.4 of the Gamemaker game engine on a Humble Bundle many years ago. At the time Gamemaker ONLY ran under Microsoft Windows. It was possible to export games to Linux (Ubuntu/Debian-specifically), but you couldn’t run the game engine itself under Linux. Version 2.x came along, and I paid to upgrade to 2.x as well.\nSome time between when I bought 1.4 and 2.x I started working on my Asteroids-like clone, Fasteroids: (https://chaslinux.itch.io/fasteroids). Many professional developers suggest starting and finishing a project as quickly as you can, then moving on to something else. Of course I didn’t listen and kept adding “features” to Fasteroids, which lead to the game being pretty messed up, and me losing interest.\nThen Opera bought YoYo games and turned Gamemaker into a subscription model… this made me swear off Gamemaker, despite the fact that I really enjoyed working in GML. But Opera did one thing that’s made me reconsider, they made a version of the engine that runs under Linux.\nCan you code a game simple in Linux? Part of my day job involves refurbishing computers with Xubuntu Linux (Update: Linux Mint) and promoting them among the community as a less expensive alternative to new or refurbished systems with Microsoft Windows. Asking people to make the leap from Windows to Linux can be a big challenge. The past couple of days I asked myself the question “what would be the best game engine to use in Linux?”\nThe most obvious answer to the question above, given what I know about Linux, is the Godot game engine. Godot exists in the Xubuntu/Ubuntu software repositories, so it can be installed right from the “software” program in Xubuntu – no extra files needed from the Internet.\nI tried Unity, the big kahuna of game engines, a couple of days ago, and despite everything working, the experience wasn’t as good as the brief experience I’ve had with Godot under Linux. This left me wondering, how bad could the Gamemaker beta for Linux client be? Could I actually code a game with it?\nI’m happy to say the answer is a definite “Yes!”\nGamemaker engine for Linux? What engine? Opera, the company that bought out Yoyo Games, the previous company behind the Gamemaker engine, hasn’t made it obvious where you can download the Linux version. The Windows and MacOS versions of Gamemaker are pretty easy to find, but there’s no obvious links on their web site to the Linux version, which is a shame, because despite their “this could corrupt your game files” warning, I found the engine to be stable enough that when I shut down with a project open, the project was fine when I started up again.\nI have since put many of the steps here into a shell script. The script doesn’t download the GameMaker engine Debian package, but it installs all the dependencies the engine requires for Xubuntu 24.04.2. You can clone the script from github at: (https://github.com/chaslinux/gamemaker-install)\nTo download Gamemaker for Linux you’ll first have to satisfy some dependencies, open a terminal and enter the following commands:\nsudo apt update sudo apt install build-essential openssh-server clang libssl-dev libxrandr-dev libxxf86vm-dev libopenal-dev libgl1-mesa-dev libglu1-mesa-dev zlib1g-dev libcurl4-openssl-dev ffmpeg libfuse2 curl -y The first command updates the online software library. The second command downloads and installs several libraries and programs Gamemaker uses. Now we need to download some Steam-related files needed by Gamemaker. Note: you don’t need a Steam account, these are for Steam support within Gamemaker (Software Development Kit).\nsudo mkdir /opt/steam-runtime/ curl https://repo.steampowered.com/steamrt-images-scout/snapshots/latest-steam-client-general-availability/com.valvesoftware.SteamRuntime.Sdk-amd64,i386-scout-sysroot.tar.gz | sudo tar -xzf - -C /opt/steam-runtime/ A great feature of newer versions of Gamemaker is the ability to make AppImages. AppImages are awesome because they can be run on any Linux distribution that supports “fuse.” What this means is you can develop a game on Xubuntu/Ubuntu and run it on Fedora Linux without needing to make any changes to the code. The same AppImage that runs on Ubuntu will run on Fedora Linux.\nwget https://github.com/linuxdeploy/linuxdeploy/releases/download/continuous/linuxdeploy-x86_64.AppImage sudo install -m 0755 linuxdeploy-x86_64.AppImage /usr/local/bin/linuxdeploy wget https://github.com/AppImage/AppImageKit/releases/download/continuous/appimagetool-x86_64.AppImage sudo install -m 0755 appimagetool-x86_64.AppImage /usr/local/bin/appimagetool Finally, get the .deb (Ubuntu/Debian package) for Gamemaker from:\n(https://gms.yoyogames.com/ReleaseNotes-NuBeta.html)\nClick the Ubuntu download and install the .deb file using the software centre. Gamemaker can now be found in the whisker menu under Xubuntu, just open the menu and start typing gamemaker.\nThis beta version only makes games for Opera’s gx.games. In order to compile for other targets you’ll need to purchase a Creator ($4.99USD/mo), Indie ($9.99USD/mo), or Enterprise license ($79.99/mo). Indie adds exporting to web and mobile (other than gx.games), Enterprise adds exporting to consoles.\nMonthly subscription is not the way to go Shortly after I initially wrote this article I contacted the GameMaker team indicating I didn’t want to buy month-to-month, but would be happy to buy a year worth of GameMaker (I despise monthly subs). Not long after the team switch back to the 1 time payment model… And they granted me a professional license for buying the year sub. This is one of the reasons I’ve stuck with GameMaker, it seems the team really do care about the community. I’ve kept the post as I initially wrote it, but am adding this to show the team changed the model for the better.\nI feel the monthly subscription model Opera has chosen for Gamemaker is not going to attract new developers to Gamemaker. When I bought Gamemaker 1.4, it was 7 months before I started using Gamemaker. Some argue that you’re more likely to use software if you’re paying for it each month, but I’m not convinced, here’s why:\nMany years ago I picked up a book something like “Learn MySQL in 24 hours.” I spent the first couple of days going through the first six chapters of the book and then I got stuck, really stuck. I put the book down for approximately 6 months, then picked it up again and wondered “how the heck did I get stuck on that problem…” I’d learned the answer somewhere else, but I needed to step away from MySQL for awhile and come back to it. I can see something like this happening with Gamemaker as it’s sometimes difficult just to bend your head around game design principles.\nOne of the reasons I promote Free and Open Source Software is that it tends NOT to have a monthly subscription model.\nPing pong When I first started learning Gamemaker years ago I found Sara (ne: Shaun) Spalding’s tutorials really helpful. So when trying out Gamemaker under Xubuntu I wanted a fast way to create a basic game… I chose Sara’s Pong tutorial as a quick (in under 15 minutes) way to test creating a game:\n(https://www.youtube.com/watch?v=yjt75sdH9h8)\nIt took me a bit more than 15 minutes, but not a lot more (25 at most) to complete this tutorial. One of the problems I ran into is when I created resources using a hot key combination, they didn’t automatically get assigned to the appropriate tree structure area. For example, if I created a sprite, or an object, both were at the bottom of the Asset Browser, below Timelines. I needed to drag the sprites and objects up to their appropriate area – something a complete Gamemaker newbie might have missed.\nThat said, the game worked!\nFig 1. Pong game made using GameMaker under Linux\nOverall impressions I really like Gamemaker as an engine. It looks like Opera is doing some good things with Gamemaker… but the monthly subscription is a bit of a show-stopper for me. I’d prefer to buy the engine outright every couple of years rather than pay a monthly subscription. I work full time, and creating games is a hobby for me. I know some people pay monthly subs to play games like Warcraft, but that’s never been my thing. I prefer to just buy something once or twice. I don’t like “yet another thing I have to track every month…”\nGamemaker shows promise under Linux. The engine was stable enough that when I shut down the computer with Gamemaker and my project open, nothing got corrupted.\nI expect I will probably transfer my game-making skills to Godot, which is completely free. I’m going to try sticking with Gamemaker for a bit and give some updates as I discover new things about the engine under Xubuntu Linux.",
    "description": "Previous GameMaker experience I bought version 1.4 of the Gamemaker game engine on a Humble Bundle many years ago. At the time Gamemaker ONLY ran under Microsoft Windows. It was possible to export games to Linux (Ubuntu/Debian-specifically), but you couldn’t run the game engine itself under Linux. Version 2.x came along, and I paid to upgrade to 2.x as well.\nSome time between when I bought 1.4 and 2.x I started working on my Asteroids-like clone, Fasteroids: (https://chaslinux.itch.io/fasteroids). Many professional developers suggest starting and finishing a project as quickly as you can, then moving on to something else. Of course I didn’t listen and kept adding “features” to Fasteroids, which lead to the game being pretty messed up, and me losing interest.",
    "tags": [
      "Game Development",
      "Gamedev",
      "GameMaker",
      "Linux",
      "Xubuntu",
      "Programming"
    ],
    "title": "Initial GameMaker experience under Xubuntu Linux",
    "uri": "/posts/initial_gamemaker_experience_under_xubuntu_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Programming",
    "uri": "/categories/programming/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Programming",
    "uri": "/tags/programming/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "After this experience, and some back and forth with GameMaker, the GameMaker team switched the licensing back to a one time fee (except for console exports), and they released a beta version of the engine for Ubuntu-based systems. The team continues to update this beta along with the normal code. Since I previously had experience with GameMaker I’ve decided to stick with it. I’ve been really thrilled with it as bugs I’ve run into have been fixed a short while after I’ve reported them, and the community have been great helping me solve issues.\nThe king of game engines Unity is considered the big kahuna of game engines. It is often cited as the best engine to learn if your end goal is to work in the game industry. Unity is cross-platform, meaning it can run on different operating systems. It can also compile programs for more than a dozen other platforms the engine itself doesn’t run on.\nI have very little experience with the Unity game engine. I bought a few online tutorials, and a book about a year ago, but when I started reading I found most of the documentation was extremely user-interface heavy, and didn’t get into coding. Four chapters into the book I’d bought and I’d yet to write a single line of code. It was a frustrating experience compared to GameMaker, where I was writing code within the first 10 minutes of watching a video. But because Unity is used so much for mobile development I thought I’d give it another shot.\nInitial problems / conflicts with Xubuntu key-mapping When I first tried the Unity game engine I discovered both Xubuntu Linux and Unity bump heads over the use of the ALT key. Normally, most key bindings can be reassigned in the “keyboards” program in Xubuntu, but in this case the ALT key keybinding was assigned in the “window manager tweaks” program.\nOpen the Window Manager Tweaks program Click the Accessibility tab Change the “Key used to grab and move windows:” from the ALT key to one of the other options, or set it to None. If you leave this key assigned to ALT, when you start to use Unity’s built-in editor to adjust 3D objects you’re going to run into issues trying to adjust those objects – Unity needs the ALT key (as do other engines).\nYou can’t just install Unity hub\nInstalling Unity is not difficult, but the default experience will not be the same as what you see in tutorials. If you have a bit of command-line experience in Linux, or can just copy and paste, you won’t have much trouble getting the Unity hub installed. Follow the instructions here:\n(https://docs.unity3d.com/hub/manual/InstallHub.html#install-hub-linux)\nOnce Unity hub is installed you have to agree to their license, set up an account, and install the Unity editor. Note: the Unity editor is not the same as Visual Studio Code. The Unity editor is the main interface you’ll see working with Unity. It consists of 4 main windows: Hierarchy, the Scene/Game window, the inspector and the project/console window.\nVisual Studio Code comes into the scene when you create a script within Unity… but Visual Studio Code doesn’t get automatically installed in Unity hub. By default, I found Unity opened Mousepad, the default text editor in Xubuntu, when I first tried creating a script. Mousepad knows about C#, but doesn’t offer the level of support for C# that VS Code does. I installed VS Code by downloading and double-clicking on the .deb package here:\n(https://code.visualstudio.com/download)\nI then installed the required .NET SDK by following the steps here:\n(https://learn.microsoft.com/en-ca/dotnet/core/install/linux-ubuntu-2204)\nYousuf Azad Sami has a nice brief article on connecting all these parts. Once VS Code is installed, Unity still needs to know about VS Code. Check our Yousuf’s article here:\n(https://medium.com/@sami.yousuf.azad/set-up-visual-studio-code-for-unity-in-linux-69b7f4352e0b)\nBut even with VS Code installed I found the experience didn’t quite match what I was seeing as I was following a tutorial. VS Code let me do some command-completion, but generally didn’t offer as many suggestions (drop downs) as I was seeing in the tutorial. These seemed to be Unity-specific. There may be an add-on VS Code needs to know about on Linux that it knows when installed on Windows.\nFor experience developers this missing feature (drop down suggestions) might be annoying, but for someone like me, someone new to learning Unity, it feels like a really important feature. I opened VS Code and clicked on the Extensions, then searched for unity. There was a Unity debugger extension that looked official, but it’s been depreciated. The closest thing I could find to the feature was the Unity Code Snippets add on by Kleber Silva, but it didn’t appear to be an official Unity plug-in – so use at your own risk.\nSlowness I have to mention the Godot game engine here because installing and using Godot is 1000x faster than using Unity. I installed Unity on a couple of Xubuntu machines:\nAn ASUS desktop featuring a Core i7-4770 @ 3.9GHz (4 cores, 8 threads) CPU with 16GB DDR3 RAM. A custom workstaion with a XEON XEON E5-2690v2 (10 core, 20 threads) CPU, with 64GB of DDR3 RAM and an NVMe drive.\nUnity felt sluggish when I tried compiling my program on my XEON workstation. I cannot imagine trying to develop a game on a machine that’s less powerful than either of these machines. To be fair, there is a wait when you click “play” on Gamemaker, but it’s a lot more clear on Gamemaker that the engine is busy. On Unity I couldn’t tell whether it ran into an issue with the code, or whether it was just delayed running the game. A few times I clicked play to run the game, nothing seemed to happen for a bit. I clicked play again, and then the game ran, or spat out an error message. The delay was just too much. At least with Gamemaker I could see an error in the inspector window. And Godot, well, that engine just runs like the wind.\nThe results First, I want to give a shout out to Game Maker’s Toolkit for their excellent Unity Tutorial for Complete Beginners, this was one of the first Unity videos I’ve watched where I felt like I was really learning the engine. Although it’s been a very long time since I’ve been in school, watching this video felt like I was connecting with the teaching style of the teacher. You can see the GMT video here:\n(https://www.youtube.com/watch?v=XtQMytORBmM\u0026t=1502s)\nI spent quite a bit of time creating my own sprites for the game in Aseprite. Aseprite is a sprite creation program available for Linux through Steam. There was an old version floating around the Internet that was (legally) free, but Aseprite was inexpensive enough that I just bought it outright. The tutorial is only 45 minutes long, but I only managed to get roughly 25 minutes into the video last night.\nMy version of the game doesn’t look anywhere as smooth as the tutorial, and my bird rotates when it collides with the stalactites/stalagmites in my game. My C# code isn’t any different than the Tutorial, but my stalactites have multiple hit boxes, which might be part of the issue.\nI plan on working completely through the tutorial in this evening, but I’m not sure I’ll continue with Unity as I really don’t like the huge delay when running the game within Unity.\nGamemaker has a Linux version of the engine, but it comes with the warning that it may corrupt your projects. I like a lot of things about Gamemaker, but I suspect that in the end I’m going to end up spending much more time in the future learning Godot, as the performance and stability on Linux is top notch. Other than the aforementioned issue with the ALT key and Xubuntu, Godot works pretty flawlessly in Xubuntu, and it takes seconds to install. That said, I don’t have a lot of experience with Godot, but the brief experience I have makes me think this is the engine to stick with on Linux.",
    "description": "After this experience, and some back and forth with GameMaker, the GameMaker team switched the licensing back to a one time fee (except for console exports), and they released a beta version of the engine for Ubuntu-based systems. The team continues to update this beta along with the normal code. Since I previously had experience with GameMaker I’ve decided to stick with it. I’ve been really thrilled with it as bugs I’ve run into have been fixed a short while after I’ve reported them, and the community have been great helping me solve issues.",
    "tags": [
      "Game Development",
      "Gamedev",
      "Unity",
      "Xubuntu",
      "Linux",
      "Programming"
    ],
    "title": "First experience trying to learn Unity on Xubuntu Linux",
    "uri": "/posts/first_experience_trying_to_learn_unity_on_xubuntu_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Unity",
    "uri": "/tags/unity/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Asteroids",
    "uri": "/tags/asteroids/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Reviving an old project Today I realized that, since redoing this web site, I still haven’t added any information about the game I made back in 2017-2020. Recently I revived Fasteroids, and made some changes to both simplify the game, but also with the idea that the game should be able to scale to 4k in the near future.\nBefore I ramble on more, you can download Fasteroids for Linux or Windows from:\n(https://chaslinux.itch.io/fasteroids)\nNote: I’ve since squashed some bugs from version 2.39, and removed this old version. Use version 2.40. This is a repost from the old web site. While I haven’t worked on Fasteroids in the past few weeks, it’s still on my radar.\nVersion 2.37 of Fasteroids is an old version I released back in 2020. The latest version of Fasteroids is 2.39. Version 2.37 of Fasteroids is dramatically different from 2.39. Version 2.37 targeted one resolution 1024×768. All menus and visual elements were made to fit that screen size. Version 2.37 also only worked with *buntu Linux distributions up to 20.04. If you upgraded to *buntu 22.04 you were out of luck running Fasteroids 2.37 as a library that was in 20.04 isn’t the same version as in 22.04.\nThe latest version of Fasteroids I released this morning is 2.39. This new version drops the resolution of the game down to 640×360. More on the reason for the drop in resolution below (future upgrade). Another BIG difference is 2.39 for Linux is now an AppImage. This means that anyone using a Linux distribution that can run FUSE/AppImages should be able to run Fasteroids. This latest version is also compiled rather than using GameMaker’s VM runner, meaning less overhead, and theoretically better performance.\n640×360 is one of the resolutions in the 16:9 aspect ratio. The idea is that I’ll scale graphics up to other 16:9 resolutions. At this point I’m thinking about scaling the game to the following resolutions: 1280×720 (SD), 1366×768 (WXGA), 1600×900 (HD+), 1920×1080 (FHD), 2560×1440 (WQHD), and 3840×2160 (4K).\nWhile 2.39 is limited to 640×360 I’m not far off writing the code to switch to other resolutions. This is likely going to also require the Asteroids, the UFOs, the main ship, and the bonus buff’s all be redrawn. It’s been a few years since I created the original artwork (GIMP and Aseprite). Things may look a little blurry/jank until I get some more drawing as sprite creation practice in again.\nI’m using a few methods to track work:\nThe Fasteroids itch.io devlog: (https://chaslinux.itch.io/fasteroids/devlog) Trello: (https://trello.com/b/z67tqsLC/fasteroids) Google Docs – this one is for my own notes when I’m not at home If you’re on Xubuntu (or another) Linux, you might need to set the AppImage to be executable. Right click on the Fasteroids-2.39.AppImage, select Properties, switch to the Permissions tab, then check the check box that says “Allow this file to run as a Program.”\nOr, in a terminal, change to the directory where Fasteroids-2.39.AppImage is located and type:\nchmod ugo+x Fasteroids-2.39.AppImage This should add the execute bit to the AppImage so when you next open it up it runs. For Windows there is both an Installer and a Zip file containing an EXE that can be run in place.\nOne bug I noticed with Xubuntu Linux is that it does not seem to display AppImage icons correctly. If you download the Fasteroids AppImage you’ll see that it looks like every other AppImage on Xubuntu, a silver box with a gear. Linux Mint XFCE seems to display the icon correctly. I’m not sure what they have implemented that the Xubuntu project hasn’t, but I hope a fix is in the future.\nFig 1. AppImage icons show on Linux Mint XFCE\nIf you enjoy the game please reach out to me on Mastodon: @chaslinux@techhub.social.",
    "description": "Reviving an old project Today I realized that, since redoing this web site, I still haven’t added any information about the game I made back in 2017-2020. Recently I revived Fasteroids, and made some changes to both simplify the game, but also with the idea that the game should be able to scale to 4k in the near future.\nBefore I ramble on more, you can download Fasteroids for Linux or Windows from:",
    "tags": [
      "Game Development",
      "Gamedev",
      "Asteroids",
      "Linux",
      "Windows",
      "SHMUP",
      "Xubuntu",
      "Linux Mint"
    ],
    "title": "Fasteroids - An Asteroids-like game for Linux and Windows",
    "uri": "/posts/fasteroids_an_asteroids_like_game_for_linux_and_windows/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: SHMUP",
    "uri": "/tags/shmup/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Windows",
    "uri": "/tags/windows/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Vikings – Wolves of Midgard (crashes after the Kalypso video) Vikings – Wolves of Midgard is a linear action role playing game (ARPG) that lets you go back and repeat quests several times until you’re overpowered. Recently I’ve tried a number of role playing games only to find they were lacking in graphics, the controls were too jank, or they just required obscene amounts of time to make any progress. I like Vikings – Wolves of Midgard, because I find that despite the fact that the story is almost aways the same, you can complete quests over and over again until you’re overpowered. The controls are not bad, especially compared to some of the games I’ve played lately. Best of all it runs natively under Linux.\nThe one big problem I’ve had with the game lately is that the game completely crashes right after the Kalypso introduction video, with no chance to play the game.\nA solution for Xubuntu Linux I found that if you moved the 3 Kalypso video files to another folder, the screen temporarily goes white, then the game loads. For me these files were located:\n/home/chaslinux/.steam/debian-installation/steamapps/common/Vikings - Wolves of Midgard/vikings_Data/StreamingAssets/videos/ On your system replace chaslinux with whatever your login username is, so if you log in with a user name of peterm it would be:\n/home/peterm/.steam/debian-installation/steamapps/common/Vikings - Wolves of Midgard/vikings_Data/StreamingAssets/videos/ In the videos folder I simply created a folder called temp and I moved logo_kalypso.mpv, logo_kalypso.ogv, and logo_kalypso.webm to the newly created temp folder.\nAfter doing this the game launched and I was able to play.\nFig 1. Vikings, Wolves of Midgard - inventory",
    "description": "Vikings – Wolves of Midgard (crashes after the Kalypso video) Vikings – Wolves of Midgard is a linear action role playing game (ARPG) that lets you go back and repeat quests several times until you’re overpowered. Recently I’ve tried a number of role playing games only to find they were lacking in graphics, the controls were too jank, or they just required obscene amounts of time to make any progress. I like Vikings – Wolves of Midgard, because I find that despite the fact that the story is almost aways the same, you can complete quests over and over again until you’re overpowered. The controls are not bad, especially compared to some of the games I’ve played lately. Best of all it runs natively under Linux.",
    "tags": [
      "Gaming",
      "Linux",
      "Software",
      "Steam",
      "Xubuntu",
      "Linux Mint"
    ],
    "title": "[Fix] Vikings - Wolves of Midgard crashing after kalypso startup screen",
    "uri": "/posts/fix_vikings_wolves_of_midgard_crashing_after_kalypso_startup_screen/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Fantasy",
    "uri": "/tags/fantasy/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Bards Tale III – my introduction to 3D like adventure Back in the late 1980’s I worked for Simcoe Computer Consultants at the 400 Market, outside of Barrie, Ontario. The 400 Market was a mixed market of many vendors, one of which was Simcoe Computer Consultants. I spent the weekends manning the company’s booth, selling the odd item, and spreading the word about the company’s computers and services.\nOne weekend Cec, one of the company owners, mentioned that a lead from the market had helped them sell a bunch of computers, and I was welcome to pick a piece of software as a reward. I picked Bard’s Tale III, Thief of Fate, a dungeon crawling game with a 3D-like interface. Bard’s Tale III quickly became one of my favourite games, it mixed D\u0026D elements with a more urgent element where one wrong turn could lead to a face to face encounter with deadly monsters.\nLegend of Grimrock Legend of Grimrock reminds me of Bard’s Tale III. The two games have very different stories, but the interfaces feel similar, and the sense of not knowing what might be around the next bend, is common to both. Legend of Grimrock has fewer character slots, but characters are more developed with the ability to develop different skills, in addition to assigning main stat points.\nFig 1. A full party in Legend of Grimrock\nThe biggest difference between the two games is the significantly better graphics of Legend of Grimrock. Bard’s Tale III got a remaster, but I’ve only extensively played the original game. I bought the remaster of Bards Tale III, but I didn’t get very far before getting killed off, and setting the game aside. Early in Legend of Grimrock I also got killed off, but there was something about the game that made me come back to it right away, an element that intimated I’d missed some learning that would have kept me alive.\nIn Legend of Grimrock you play up to 4 prisoners tossed into the Legend of Grimrock with nothing. It’s your job to escape the dungeon. The character creation screen lets you create up to 4 characters, and choose from among 4 races: Human, Minotaur, Lizard Man, or Insectoid. Base statistics change depending on the race chosen. Humans have no positive advantages, but also no negative disadvantages. Minotaur’s have increased strength and vitality, but take a hit on willpower. Lizard Men have increased dexterity, but also take a hit on willpower. Insectoids have increased willpower, but take a hit on strength. During character creation players have the ability to assign up to 10 points across all statistics, so any negatives can be negated, or positives can be increased further, to a point. Base statistics can further be increased by choosing special “traits.” The strong mind trait, for example, adds +2 to willpower. Base stats are sometimes capped at 18, and can’t be increased further through the initial assignment points, but can be buffed beyond 18 through trait choice.\nOne of the downsides to Legend of Grimrock are the limited classes, characters be a Fighter, Rogue, or Mage. A lot of Role Playing Games of late tend to have many classes, and dozens of skills across several skill trees for those classes, allowing a lot of variety. Legend of Grimrock is simple, but simplicity is part of its charm. A word of caution, make sure you’re choosing the class you actually want to choose for each character. I inadvertently created a fighter and stuck him in the rear last slot, when I intended to create a mage, a fighter with 8 strength. Also, don’t forget to give your characters unique names, “New Prisoner” won’t hurt game play, but isn’t very original unless you’re planning a clone army.\nFig 2. A Herder mushroom - Legend of Grimrock\nRuns on a potato If you pull up Legend of Grimrock on Steam you’ll notice versions for Windows, MacOS, and Steam (note: we’re talking about the original Legend of Grimrock, not Legend of Grimrock II, which only supports Windows and MacOS). Normally, games that run on SteamOS also have a SteamOS/Linux tab in the System Requirements, but Legend of Grimrock does not. For Windows the requirements are as follows:\nProcessor: Dual Core 2GHz Intel, or 2.8GHz AMD Memory: 2GB RAM Graphics: ATI Radeon X1600 or NVIDIA GeForce 7600. Shader Model 3.0 needs to be supported. The minimum resolution for the game is 1024×768 or 1280×720 for wide screen. The above are the absolute minimum requirements, most people should look at the recommended requirements, which are as follows:\nProcessor: Quad Core 2.66GHS Intel or 3.2GHz AMD Memory: 4GB RAM Graphics: A graphics card supporting OpenGL 2.1 I ran Legend of Grimrock on a system with Intel onboard graphics (XEON E3-1200 v3/4th Gen Core processor Integrated Graphics Controller) that supported OpenGL 4.6 and it ran very smoothly. This is just to suggest it might be possible to run the game on integrated Intel graphics as well, as long as it supports OpenGL 2.1 and the resolutions mentioned before.\nSolving puzzles, wandering around, and combat Legend of Grimrock starts out slowly, but characters also start out empty handed, no weapons at all. Wander around enough and you’ll start to pick up clothes, items that can be used as weapons (tip: you can use torches as weapons), food, and other items.\nSome items can be used to solve puzzles, things that when placed strategically stop traps from springing, or open doors, or other passageways. There are hidden passageways that can be triggered by pressing parts of a wall, and messages that give hints on how to solve some of the dungeon puzzles.\nThe game starts so slowly you might think that there’s not much to the game, but be wary, there are monsters on the first level, and they can easily kill your entire party if you’re not prepared. There is no swapping characters in the middle of the adventure, you’ve been dumped down a pit into the dungeon – no escape until you burrow down into the furthest reaches.\nYou can save your game in spots. There’s an autosave, but it’s also helpful to save your game in a separate slot in case of death… which can easily happen between the game’s monsters and traps.\nFig 3. Giant slug, the first encounter - Legend of Grimrock\nGiant Slugs are the first monster encountered in Legend of Grimrock. You might expect them to be wimpy, but they take several hits from both characters in the front row, in addition to thrown weapons from the back row, to kill. Better weapons mean easier kills, but by the time you acquire better weapons you also have to deal with more difficult monsters.\nControls, a bit jank at first Legend of Grimrock uses a combination of keyboard and mouse controls. WASD is used for movement, Q and E are used to switch views, left and right. Right mouse click on an equipped weapon to use it. Only the front 2 characters can attack with melee weapons, the rear two characters have to rely on missile or spell weapons.\nAs you progress through the dungeon things become a bit confusing. Thankfully there is a slick automap that runs in the background. To bring up the dungeon map hit the TAB key. The dungeon map doesn’t stay on the screen, as it does in many RPGs. I actually like that the map disappears, it makes the game slightly more challenging.\nCost Legend of Grimrock is available on Steam for $16.99CDN + taxes. I bought the game when it was on sale for $6.52 + HST. If you don’t mind games that test your patience, than Legend of Grimrock is probably worth the full price. But if you’re looking for something like a Diablo-esque game, this really isn’t it.\nExtras There is a dungeon editor included with Legend of Grimrock, and it loads fine in Xubuntu Linux 22.04, but I haven’t actually used it to create any dungeons – the game is challenging and interesting enough that I’m still enjoying the base game. There will come a time when I’m sure I’ll appreciate the editor, but for now the game is fun enough without the editor. There are several guides for Legend of Grimrock on Steam, including a description of the skill trees and spell formulas for the mage class.\nThere is also a PDF manual if you click on the Manual in the Addition Content section of the Steam page for Legend of Grimrock (note: this only shows if you’ve purchased the game). The manual looks very nice and reminds me of the kind of quality that used to go into manuals years ago.\nFig 4. PDF Manual page - Legend of Grimrock",
    "description": "Bards Tale III – my introduction to 3D like adventure Back in the late 1980’s I worked for Simcoe Computer Consultants at the 400 Market, outside of Barrie, Ontario. The 400 Market was a mixed market of many vendors, one of which was Simcoe Computer Consultants. I spent the weekends manning the company’s booth, selling the odd item, and spreading the word about the company’s computers and services.\nOne weekend Cec, one of the company owners, mentioned that a lead from the market had helped them sell a bunch of computers, and I was welcome to pick a piece of software as a reward. I picked Bard’s Tale III, Thief of Fate, a dungeon crawling game with a 3D-like interface. Bard’s Tale III quickly became one of my favourite games, it mixed D\u0026D elements with a more urgent element where one wrong turn could lead to a face to face encounter with deadly monsters.",
    "tags": [
      "Gaming",
      "Linux",
      "Software",
      "Steam",
      "Xubuntu",
      "Linux Mint",
      "Retro",
      "C64",
      "Fantasy",
      "RPG",
      "Role Playing Game"
    ],
    "title": "Legend of Grimrock - a better Bards Tale III",
    "uri": "/posts/legend_of_grimrock_a_better_bards_tale_iii/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Role Playing Game",
    "uri": "/tags/role-playing-game/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Almost 11 years old, and still fun Torchlight II (opens to Steam page) was released in September of 2012, several months after the release of Diablo III. Max Schaefer and Matt Uelmen, both developers who worked on Diablo and Diablo II, helped form Runic Games, the company behind Torchlight II.\nWhile both Torchlight II and Diablo II are considered ARPGs (Action Role Playing Games), Torchlight II feels like it has less linear gameplay. Both games drive you to destroy an end boss, and both have side quests, but Torchlight II is purposefully moddable, and a lot less dark. In Diablo and Diablo II you fight demons, devils, undead, and other demonic monstrosities. In Torchlight II you find yourself pitted against more Dungeons \u0026 Dragons variety monsters, Mind Flayers, Werewolves, Bandits, Manticores, and a more mixed variety of monsters.\nTorchlight II doesn’t have the variety of classes of Diablo II or III, but it shines in other areas. Fishing, you can stop to fish in the middle of the wilderness, and there’s a chance of finding rare, or even unique items. The scenery in Torchlight II is a lot more varied, and it feels more 3 dimensional. When you go up a hill it feels like you’re going up a hill, and not an isometric drawing. Another great feature of Torchlight II is the ability to send your pet to town in order to sell equipment you’ve collected, and buy potions and teleport/identify scrolls..\nFig 1. My level 31 Berserker, Duke, at the Imperial Camp\nClasses in Torchlight II s mentioned earlier, classes in Torchlight II are a bit weak compared to Diablo II, or III, but an interesting side effect is that all classes have 4 scroll slots that act like extra abilities. The classes in Torchlight II are Berserker, Embermage, Engineer, and Outlander. Given the right stat arrangement any class can use any weapon not marked specifically for a particular class. That said, the classes tend towards particular weapons. Berserker, for example, tends to be a dual claw-wielding class. But the level 31 Berserker shown above is wielding a sword and a unique claw. Embermage’s tend to use wands, (they can dual wield wands), or a single staff. Engineers are oriented towards heavy two handed melee weapons, though they also have skills related to hand cannon use. Outlanders tend to be the gun-wielding class, with both hand guns and shotguns featured.\nOf all the classes Outlander is my least favourite because of the movement, it’s just hard to get used to a class that flips backward rather than forging ahead. The other 3 classes all have movement skills that increase their distance going forward.\nSkill trees Similar to other ARPGs, Torchlight II has skill trees you can progress through as you advance in level. Each class has 3 skill trees that focus on different aspects of the class. Lately I’ve been playing the Engineer class and my main focus has been advancing the Blitz tree, in particular the first skill Flame Hammer. The Engineer class also has a couple of other skill trees: Construction, which is built around summoned robots, and cannon skills. Aegis is a shield-based skill tree that also features some other defensive skills.\nFig 2. Engineer skills - Torchlight II\nEvery 5 points in an active skill adds a bonus to the skill. Passive skills don’t add extra bonuses after 5 skills. One of the downsides to Torchlight II is that you cannot completely re-spec your skills. You can remove the last 3 points assigned, but not a complete re-spec. This means thinking a bit before investing in skills.\nCooperative online play I played through Torchlight II with a group of 3 other people over a period of several weeks. Cooperative play is fun, and adds the benefit of more loot available through trading. One thing that annoys me quite a bit about Torchlight II is that I find more Unique equipment that isn’t for my class, than is for my class. There is a vendor who can “re-roll” equipment, but it takes 4 unique pieces of equipment to create 1 re-rolled piece of equipment, and my luck has mostly been unique equipment that doesn’t fit the class I’m playing. Group play solves this problem a bit, especially if everyone chooses a different class.\nFig 3. Spoils of defeating a Djinn - Torchlight II\nWorks on my Lenovo ThinkPad T430s Torchlight II works really well on my Lenovo ThinkPad T430s laptop, running Xubuntu 22.04. While I haven’t tried running Grim Dawn, another ARPG, on the T430s, Grim Dawn has issues with my 10 core 20 thread workstation, so I expect it doesn’t work well on the the T430s. It’s worth mentioning that my T430s has the best screen available for that model. Some T430s’ only have a 1366×768 screen, my particular model has a nice 1600×900 resolution screen. While not 1080p, the game looks and runs great at 1600×900.\nTorchlight II has Windows, MacOS, and SteamOS+Linux variations of the game. I’ve always just played the Linux version as it works really well in Xubuntu 20.04 and 22.04. System requirements are pretty minimal, a 2.0GHz CPU, 2GB of RAM, and an OpenGL 2.0-compatible video card with 256MB of VRAM (Video RAM).\nFig 4. The Salt Barrens waypoint portal in Torchlight II\nCost $21.99CDN might seem like a fair amount for a game made in 2012, but Torchlight II frequently goes on sale, and it’s worth mentioning that the Mods system lets you add a bunch of mods for free, unlike games like Grim Dawn where you pay for extra DLC. Visit the Torchlight II Workshop page for a good list of downloadable mods (without the need to sign up for something): (https://steamcommunity.com/workshop/browse/?appid=200710)\nSome mods increase the drop rate of items, others are completely new classes. So while vanilla Torchlight II is limited to 4 classes, mods can add a whole slew of new classes, monsters, weapons, etc. Yes, if you want Pokemon Pets, that’s possible with a mod. If you like the darker look of Diablo, there’s a mod for that. I previously mentioned that one of the downsides to Torchlight II is the fact that you cannot completely re-spec your character. Yes, there’s a mod for re-specing too.\nOverall, despite the age of the game, I find myself drawn back into the world of Torchlight II. It might be old, but the flexibility of the game makes it playable, even in 2023.",
    "description": "Almost 11 years old, and still fun Torchlight II (opens to Steam page) was released in September of 2012, several months after the release of Diablo III. Max Schaefer and Matt Uelmen, both developers who worked on Diablo and Diablo II, helped form Runic Games, the company behind Torchlight II.\nWhile both Torchlight II and Diablo II are considered ARPGs (Action Role Playing Games), Torchlight II feels like it has less linear gameplay. Both games drive you to destroy an end boss, and both have side quests, but Torchlight II is purposefully moddable, and a lot less dark. In Diablo and Diablo II you fight demons, devils, undead, and other demonic monstrosities. In Torchlight II you find yourself pitted against more Dungeons \u0026 Dragons variety monsters, Mind Flayers, Werewolves, Bandits, Manticores, and a more mixed variety of monsters.",
    "tags": [
      "Gaming",
      "Linux",
      "Software",
      "Steam",
      "Xubuntu",
      "Linux Mint"
    ],
    "title": "Torchlight II for SteamOS and Linux",
    "uri": "/posts/torchlight_ii_for_steamos_and_linux/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "About findmonitor.sh Note: Note: This script is NOT compatible with systems running Wayland. We use Xubuntu Linux at our project.\nThe Working Centre’s not-for-profit Computer Recycling Project sometimes receives donations of many monitors all at once. Our previous method for handling monitors was to set them up, run them through a bunch of tests, print a label on our label printer, and enter the monitor into our point of sale. This method hasn’t worked very well for us when we’ve received a lot of monitors all at once. Large amounts of monitors were sitting untested for awhile because we didn’t have the resources to do the old process for each monitor. We needed a faster way to figure out some of the details of monitors, and make them easier to sell without needing to create labels and enter everything into the point of sale.\nFig 1. Updated version of the script adds a price\nEnter my findmonitor.sh script available on github at: (https://github.com/chaslinux/findmonitor/). The findmonitor.sh Linux BASH shell script uses a couple of tools, xrander and ddcutil, to create a PDF on the user’s desktop with information about the monitor connected to the system.\nBenefits of using the script If you have to process a bunch of monitors, findmonitor.sh can be quite handy. The script produces a PDF that includes the manufacturer name, model of the monitor, maximum resolution, and sometimes includes information about the connections on the monitor (this depends on ddc information, which not all monitors support). The PDF also has a barcode that’s produced based on the serial number of the monitor. This comes in really handy because you can use a barcode reader to scan the barcode into your point of sale, or spreadsheet, making data entry simpler.\nThe findmonitor.sh shell script collects EDID and DDC information from monitors. The script then produces a single letter-size page PDF with a box around the following monitor information:\nManufacturer Model Serial Number Resolution Date of manufacture If the monitor also supports DDC, and the DDC information is correctly filled out by the manufacturer in the monitor’s firmware, it will show the inputs on the back: VGA/DVI/HDMI, DisplayPort.\nThe script also takes information from the monitor’s Serial Number and produces a barcode, making it easy to input into a Point-Of-Sale system.\nAs of this post, the script now also produces a price in the top right corner, based on the size of the monitor. In the script I’ve set prices as:\n24\" - $30 22\" - 23\" - $20 20\" - 21\" - $10 17\" - 19\" - $5 anything unrecognized or smaller gets a $SEE STAFF price All these are easily changeable in the script. The feature image at the top of this post shows changes between the old version (left) and the new version (right).\nShortcomings of the script Currently the script has several shortcomings. Some of the problems involve garbage in, garbage out situations where manufacturers don’t fill out EDID information about their monitors. For example, there’s a field for serial number, that often isn’t filled out by manufacturers, so the resulting serial number isn’t always accurate. Of course this also means the barcode may end up not being what’s expected. There are a couple of fields for serial number, if a manufacturer doesn’t fill out the main serial number field, the script looks at another serial number field, which isn’t the normal one on the back of the monitor, but should be unique.\nAnother shortcoming is that the script doesn’t always process monitors correctly without a reboot of the computer. We noticed this with monitors that ONLY had VGA connections. Most monitors with DVI (except one or two) could be hot swapped, the script rerun, and new information generated for the new monitor. We tested this with HDMI and it also seems to be okay for hot swapping, but check the resulting PDF just to make sure it isn’t the previous monitor.\nThis script is intended for desktop monitors, not laptops.\nThis script is also wasteful. The PDF it generates has a box in the middle of a page. What we do at the project is make a couple of cuts vertically and staple that normally wasted paper together to use as a message scratch pad beside out telephone.\nInstalling the script The script is hosted on github. The simplest way to install the script is to clone it using git and do updates with git pull. First install git if you haven’t already:\nsudo apt update sudo apt install git Next make a directory to clone the repository into. You can clone it into your home directory, but I like to clone things into a sub-directory. Making a sub-directory ensures you keep your home directory clean. I like to clone projects into a directory called Code.\nmkdir ~/Code Next, change into the directory where you want to put the findmonitor project and clone the project:\ncd ~/Code git clone https://github.com/chaslinux/findmonitor This will make a directory called findmonitor inside the Code directory. In that ~/Code/findmonitor directory will be the findmonitor.sh script. Change into the directory and run the script:\ncd ~/Code/findmonitor ./findmonitor.sh If you’re unfamiliar with Linux, it’s important to note that Linux treats small and capital letters differently. So Code and code are different directories in Linux. If you’re used to Windows, this is one difference worth knowing. The first line changes into the ~/Code/findmonitor directory. Note: ~ is a shortcut for the currently logged in user’s home directory. If your username is chaslinux, cd ~ would take you to /home/chaslinux. If your username is linuxuser, cd ~ would take you to /home/linuxuser. Putting a period and forward slash in front of the findmonitor.sh script name tells the BASH shell to run the program.\nOccasionally you may run into a situation where a script doesn’t run. I sometimes make a change that affects whether the program is run-able, and forget to set the executable bit. To make a script executable run the following command:\nchmod ugo+x findmonitor.sh Note: you need to be in the directory findmonitor.sh is in, in order to set the executable bit.\nChmod stands for change file mode. The u after chmod stands for user, g for group, and o for others. With the command above we are adding the +x executable bit to the user’s account, the group’s account, and any others. This means anyone who can access the directory can also execute the script. Be careful setting the execute bit on programs you don’t know, or don’t have access to the code to. Allowing any user to execute a program could be a vector into your system, particularly if you don’t know what the program does, but also if the program is written in a way that touches other parts of the system.\nThe findmonitor.sh script should be run as a non-root user, but with sudo access. On Ubuntu/Xubuntu/Kubuntu and other Ubuntu-derived distributions this is the first user you created. Don’t run the script with sudo, it will prompt you for the sudo password.\nBefore running the script Before you run findmonitor.sh, for best results run on monitors with a digital connection. This means DVI, DisplayPort, or HDMI. If you run on a system with DSUB/VGA be prepared to log-out or reboot each time, or the script will produce information for the last monitor.\nBe aware: Not all manufacturers add all EDID or DDC information, but this script tries to make a best guess. Some manufacturers do no fill out the main serial number field, but use another serial number field. Or the serial number field is only partially filled compared to what you might find on the back of the monitor.\nNotes about the PDF The PDF produced is a full page PDF for a single monitor. This is wasteful. What we do at our project is turn the page and cut the long strips of paper away from the rectangle. These long strips are then stapled together and used as scratch pads by our phone. The other small pieces are recycled in our paper recycling, or used as a quick price tag for something else.\nHow price is determined We’ve based price on monitor size. As mentioned earlier, we charge $30 for a 24″ monitor, $20 for a 22″ monitor, and so on. Sadly there is no EDID information that indicates monitor size. We use the monitor model as a best guess for the size of the monitor. For example: the Dell U221H monitor in the image is parsed as a 22″ monitor and gets a price of $20. The script trims the letters out of the model, then cuts the model to the first couple of characters. On some models this doesn’t work. For example: The BenQ FP951 is detected, but when the script parses this it ends up being read as 95, not a 19″ monitor, so a price of Price: $SEE STAFF is produced.\nIt’s not a perfect script, but it works for a lot of monitors.\nUpdates When the script is updated on github it’s possible to get new updates by changing into the findmonitor directory and doing a git pull (provided you haven’t made your own changes):\ncd ~/Code/findmonitor git pull I update the script from time to time. At the moment I’m just working on adding new monitor manufacturers, but I plan on adding support for other Linux distributions in the near future. Also, this script currently doesn’t work for systems running the Wayland display system.\nIf you find findmonitor.sh helpful If you find the findmonitor.sh script helpful, I’d love to hear from you. This project was started for our not-for-profit computer refurbishing project, but I’d love to see it get used elsewhere. Feel free to reach out to me via email, my email is in the script, or via Mastodon: @chaslinux@techhub.social.",
    "description": "About findmonitor.sh Note: Note: This script is NOT compatible with systems running Wayland. We use Xubuntu Linux at our project.\nThe Working Centre’s not-for-profit Computer Recycling Project sometimes receives donations of many monitors all at once. Our previous method for handling monitors was to set them up, run them through a bunch of tests, print a label on our label printer, and enter the monitor into our point of sale. This method hasn’t worked very well for us when we’ve received a lot of monitors all at once. Large amounts of monitors were sitting untested for awhile because we didn’t have the resources to do the old process for each monitor. We needed a faster way to figure out some of the details of monitors, and make them easier to sell without needing to create labels and enter everything into the point of sale.",
    "tags": [
      "Computer Refurbishing",
      "Hardware",
      "Display",
      "Monitor",
      "Programming",
      "BASH",
      "Shell Script",
      "DVI"
    ],
    "title": "A Linux BASH shell script to create a PDF of monitor information - findmonitor.sh",
    "uri": "/posts/a_linux_shell_script_to_create_a_pdf_of_monitor_information_findmonitor/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: BASH",
    "uri": "/tags/bash/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Display",
    "uri": "/tags/display/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: DVI",
    "uri": "/tags/dvi/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Monitor",
    "uri": "/tags/monitor/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Shell Script",
    "uri": "/tags/shell-script/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: FFMpeg",
    "uri": "/tags/ffmpeg/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "Diminishing returns after 6 cores, but not for all media Handbrake is a video transcoder. It’s normally used to convert and compress video from a format into a more compressed format. Handbrake comes in a command line version, handbrake-cli, and a graphical version, handbrake. I’ve seen it mentioned several times that Handbrake is best at 6 cores or less, after that the encoding returns are diminishing. I thought this was the case with some of my experimentation, but it seems the answer is more complicated – it depends.\nIn this reddit thread (https://www.reddit.com/r/Amd/comments/6t0x77/do_you_know_that_handbrake_can_only_use_up_to_6/) someone by the nickname Jussi_Helle-aho comments that it depends on the media and format being converted to. Jussi suggests the limitation isn’t handbrake, but the h264 format. I’m not sure this second part is true, but the first might be. In my experimentation with my E5-1650v0 (6 core, 12 thread) and E5-2690v2 (10 core, 20 thread) I found that handbrake did tend to max out (90%+) all of my E5-1650v0 cores on DVD content, whereas my E5-2690v2 cores sat around 75-80% during the encoding process.\nHowever, if I started encoding Blu-ray content, even using x264 as an end format, all cores ramped up to between the high 80’s and mid 90’s. I set up a conky to monitor all my cores originally to try and diagnose some issues running Grim Dawn, a Windows-based ARPG that I run under Proton through Steam. The game works fine at the beginning, but as things ramp up and the game progresses, it crawls on my 10 core 20 thread system. This is a bit concerning since I have an NVMe drive, 10 cores and 20 threads, 64GB of RAM, and, a 4GB Radeon R9 380 graphics card. My system is significantly better than the minimum recommendation, and just fits the recommended settings with the CPU’s top clock at the recommended setting.\nRunning idle, the cores run at 1.20-1.50GHz. Running Handbrake on Blu-ray content, all the cores and threads shoot up to 3.29GHz with between 90-95% usage. At the end of the encoding process, cores drop back down to between 1.20 and 1.50GHz. DVD encoding is slightly different, cores eventually shoot up to 3.29 GHz, but tend to sit at 3.24-3.27 GHz for a bit, and only average 82% usage.\nI haven’t experimented yet with different codecs. VP9 seems interesting, but whether Handbrake supports it I’ve yet to investigate. GPU encoding is all the rage, but I remember reading some articles and thinking there were drawbacks to GPU encoding given my process, and it seemed more difficult to implement in Xubuntu Linux. Still, these are worth looking into as I’ve mostly switched to webp for images (vs jpeg/png) and been pretty happy with the result.\nIs it worth going out and buying an inexpensive X79/X99 CPU and motherboard combination over new technology? I don’t think so. If you already have an X79/X99 motherboard or CPU the answer might be yes depending on the processor. Newer technology tends to have instruction sets more beneficial to compression. Newer processors also tend to have higher clock speeds per core, which translates into more performance per core. I’m not sure how a processor like the Ryzen 5 5500, which was just over $115CDN last week, would fare against a $60-$80 18 core, 36 thread XEON, but I’ve been tempted to upgrade our media centre with an X99 board and processor, and my own system with a Ryzen CPU and motherboard.",
    "description": "Diminishing returns after 6 cores, but not for all media Handbrake is a video transcoder. It’s normally used to convert and compress video from a format into a more compressed format. Handbrake comes in a command line version, handbrake-cli, and a graphical version, handbrake. I’ve seen it mentioned several times that Handbrake is best at 6 cores or less, after that the encoding returns are diminishing. I thought this was the case with some of my experimentation, but it seems the answer is more complicated – it depends.",
    "tags": [
      "Handbrake",
      "Encoding",
      "FFMpeg",
      "Video Encoding",
      "Hardware",
      "Software",
      "Linux"
    ],
    "title": "Handbrake performance on more than 6 cores",
    "uri": "/posts/handbrake_performance_on_more_than_6_cores/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Video Encoding",
    "uri": "/tags/video-encoding/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "About the script I wrote the hardware.sh BASH script to make it a bit simpler for volunteers at The Working Centre’s Computer Recycling Project to figure out what hardware was in a computer. For more than a dozen years we’ve been asking volunteers to gather information from the BIOS, or using phoronix-test-suite under our PXE booted Debian Live environment. Volunteers would write the information on quarter page-sized sheets we would attach to each computer. While this was a useful function to help volunteers get to know hardware in a computer, there were a few problems with this method:\nNot everyone prints legibly. Some of the “spec” sheets were difficult to read, with 8’s being confused with 0’s, 9’s and 4’s being confused, and so on. Information wasn’t always accurate. Mistakes were made transferring between what phoronix-test-suite suggested and what was written on the paper. Inconsistent amounts of information were being written down. One person would fill out a spec sheet completely, while another would leave sections blank. The Serial Number of an OEM was often left off the sheets. We used these serial numbers in our point-of-sale, having them on the spec sheets saved lots of time. Non-OEM systems don’t have a serial number, so we were having to show volunteers how to get the MAC address of the network card in a system to use as a serial number. I also considered the fact that just reading off system information from phoronix-test-suite really isn’t giving the volunteers the educational value of learning parts of the system. While this script doesn’t serve that purpose either, it does simplify a few things.\nHardware.sh installs a bunch of tools to query the computer it is run on. During the script, hardware.sh produces several files on the desktop of the currently logged-in user, which are deleted until 2 files remain, specs.tex and specs.pdf. Specs.tex is a LaTeX file which is used to create specs.pdf. While the LaTeX file isn’t needed, I use it sometimes to improve the script when people run into issues with the script.\nThe resulting PDF is a full 8 1/2 inch by 11 inch page with a significant amount of information:\nOEM manufacturer, model/product name, family, and serial number. For non-OEM systems some of these fields do not exist or are listed as “To be filled out by OEM.” I’ve written the script to set the serial number to the NIC MAC address of systems where there is no OEM. CPU manufacturer, model, core, and thread count. RAM amount, maximum RAM capacity, and the type (for example: DDR3) of RAM. Graphics model, video RAM, and OpenGL support information (which can be useful for Linux games on Steam). Hard Drive manufacturer (model family), model, and capacity. DVD Drive information (this can be helpful if you run into issues where a DVD drive’s firmware might need to be updated). Network information, including wireless information. Sound information. For laptop computers the PDF also includes:\nBattery design capacity, and the last full capacity of the battery. Resolution of the laptop LCD. Known bugs Hardware.sh is far from perfect. There are several things I need to work on, and because OEM’s and manufacturers do not always fill out information fields about their products, the script cannot always give all the information above for every product.\nFor example: On a Lenovo ThinkPad X61 the script shows the RAM installed, maximum capacity, and the fact that the RAM is DDR2. On the Acer AT3-710 desktop I’m on hardware.sh shows the RAM installed, maximum capacity, the fact the RAM is DDR3, and the memory speed of the installed RAM.\nFor systems where manufacturer information is filled out as “To Be Filled Out By OEM” some areas will be lacking, or incorrect.\nWe only install 1 hard drive in most systems. Currently the script is limited to detecting only one drive. If you have multiple drives, only the first detected drive will be shown (unless it’s NVMe + HDD).\nUpdate: The script can now detect multiple hard drives, or one SSD/NVMe plus hard drives, but it still doesn’t account for multiple SSDs. Our project receives so few SSD/NVMe drives that we don’t build systems with multiple SSDs.\nWhy so many dependencies? When the script was originally developed, it only installed a handful of other programs. When I added the ability to embed a barcode (of the OEM serial number or MAC address if a custom build), that added dozens of extra dependencies to the script. Since the embedded barcode is one of the more handy features of the script the dependencies are staying.\nWhy this script is useful? Most hardware spec tools don’t cover the amount of information this script generates. It generates a barcode based either on the OEM serial number in the case of manufacturers like Dell, HP, Acer, or based on the MAC address of the network card for non-OEM systems. This barcode can be scanned with a hand scanner, making data entry into Point of Sale systems, or tracking systems, easier.\nDownloading and running the script This script is intended to be run on Ubuntu-derived systems, but may work on other Debian-based systems with a bit of tweaking. Initially, the script was tested on Xubuntu 20.04 and 22.04, but has since been updated for Xubuntu 24.04.2 and Linux Mint from 21.3 to 22.1. I recommend running updates before running the script:\nsudo apt update \u0026\u0026 sudo apt upgrade -y First make a directory to hold the script. I’ve been working on several scripts for our project and have been putting all the scripts in a directory named code:\nmkdir ~/Code cd ~/Code Next install git:\nsudo apt install git -y Then clone the hardware.sh github repository:\ngit clone https://github.com/chaslinux/hardware.sh Now change into the hardware.sh directory and run the script:\ncd hardware.sh ./hardware.sh Note: if the above doesn’t work try:\ncd ~/Code/hardware.sh ./hardware.sh If that still doesn’t work, check to see that you cloned the hardware.sh directory inside the ~/Code directory. If the script doesn’t run check it has execute permission: chmod ugo+x hardware.sh. It should have all these by default, but with the heavy changes I sometimes forget to ensure the script has execute permission.\nNote: do not run this script with sudo! The script will prompt when a sudo password is needed. The user running the script must have sudo access, but the script should be run as that user, not with sudo in front of the script.\nThe script may take a bit to work. One of the first things it does it update all the packages on a system.\nIf this script is useful for your project I’d love to hear from you on Mastodon: @chaslinux@techhub.social\nNote: It’s also worth mentioning that the script does not look for SCSI drives. As I understand it modern SCSI drives use /dev/sg*. I may add this in the future, but we mostly work with desktop systems and don’t expect to put a desktop OS on a machine with SCSI drives since they’re often in servers. We have some systems with SCSI drives, so I may consider adding support for this in the future.",
    "description": "About the script I wrote the hardware.sh BASH script to make it a bit simpler for volunteers at The Working Centre’s Computer Recycling Project to figure out what hardware was in a computer. For more than a dozen years we’ve been asking volunteers to gather information from the BIOS, or using phoronix-test-suite under our PXE booted Debian Live environment. Volunteers would write the information on quarter page-sized sheets we would attach to each computer. While this was a useful function to help volunteers get to know hardware in a computer, there were a few problems with this method:",
    "tags": [
      "BASH",
      "Hardware",
      "Linux",
      "Shell Script",
      "Computer Refurbishing",
      "Xubuntu",
      "Linux Mint",
      "Computer Recycling",
      "Programming",
      "PDF"
    ],
    "title": "Hardware detection script for Linux refurbishers",
    "uri": "/posts/hardware_detection_script_for_linux_refurbishers/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: PDF",
    "uri": "/tags/pdf/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Desktop",
    "uri": "/tags/desktop/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: GNOME",
    "uri": "/tags/gnome/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Ubuntu",
    "uri": "/tags/ubuntu/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "The Computer Recycling Project used Ubuntu Linux from 2006 to 2010 It’s a challenge to talk about Xubuntu Linux without referring to Xubuntu’s more popular relative, Ubuntu Linux. Ubuntu Linux was started in 2004 and based around a then popular flavour/distribution of Linux, Debian.\nDebian Linux was the distribution The Working Centre’s Computer Recycling Project initially used to develop our own Linux distribution, WCLP – Working Centre Linux Project, way back in 2001. By 2006 the project had switched to Ubuntu Linux. Ubuntu Linux was a rising star back in 2006, it made installing “difficult to install” proprietary drivers easy (compared to Debian). And because Ubuntu was based on Debian, people with Debian experience could easily adapt to Ubuntu.\nUbuntu has changed a lot over the years. Back in 2010 Ubuntu switched the desktop environment from GNOME 2 to a desktop environment they’d been developing in-house, Unity. This was a problem for our project since many of the laptops we received at the time could not run the Unity desktop environment. At this time we went looking for a distribution/flavour of Linux that looked and worked a bit more like the Ubuntu of old. This is when the project switched to installing Xubuntu. We’ve been using Xubuntu ever since.\nThe Unity desktop was praised by many, but there was also a lot of complaints about the new environment (I suspect quite a few were for the same reason we dropped Ubuntu/Unity). Around mid 2017 Ubuntu dropped Unity for the GNOME 3 desktop environment. While the Unity desktop environment is still being developed, the featured desktop environment for Ubuntu has been GNOME 3 ever since.\nFig 1. Ubuntu 22.04 Online Accounts setup\nThe basics Besides the difference in the desktop environment, Ubuntu includes a different set of programs during the installation, than Xubuntu. When Ubuntu first starts, it encourages people to “Connect Your Online Accounts.” Ubuntu lets you integrate Google, Microsoft (cloud), Nextcloud, and Ubuntu Single Sign-On accounts during the initial boot up. The Online Accounts screen can be skipped if you don’t want to use this method to access online calendars, documents and photos. A couple of other information screens appear if you click skip, until the window switches to a “Ready to go” window. At this point clicking Done will close the initial welcome dialog box.\nUbuntu features a thick panel on the left side of the screen, and a smaller panel at the top. Nine tiny boxes, that form a box, in the bottom left of the window, open a screen of installed software when clicked. This new screen contains more software than appears on the screen and can be searched by typing the name of a program in the search field at the top.\nFig 2. Some of the software pre-installed in Ubuntu 22.04\nUbuntu’s settings program is a bit simpler to use compared to the settings program in Xubuntu. I like how settings are handled in Xubuntu. Settings in Xubuntu look similar to how settings appear in Windows 7, a window, with a number of icons to control different categories of settings.\nUbuntu takes a slightly different approach grouping different settings on the left pane of a window. Switching between different settings in Ubuntu is a matter of clicking one of the other tabs.\nFig 3. Ubuntu 22.04 settings\nWhile Ubuntu has come a long way, it is still more resource demanding than Xubuntu. On a 3rd generation Core i5 with 8GB of RAM and an SSD Ubuntu perfoms decently, but while it’s possible to install on something like an older Core 2 Duo desktop with a decent graphics card, it’s better to stick with lighter-weight options like Xubuntu or Lubuntu.\nOnline account integration is nice if you like that kind of thing, but I’ve always felt the less my computer stores sensitive passwords the better. I’ve become accustomed to Xubuntu’s default set of hot keys and some of the quirks and bugs in Xubuntu, so despite some of the nicer features of Ubuntu, I still prefer to use Xubuntu.\nNote: Ubuntu 24.04 was released in 2024, and has since been updated to Ubuntu 24.04.2. See the Ubuntu web site for more details. Ubuntu.com",
    "description": "The Computer Recycling Project used Ubuntu Linux from 2006 to 2010 It’s a challenge to talk about Xubuntu Linux without referring to Xubuntu’s more popular relative, Ubuntu Linux. Ubuntu Linux was started in 2004 and based around a then popular flavour/distribution of Linux, Debian.\nDebian Linux was the distribution The Working Centre’s Computer Recycling Project initially used to develop our own Linux distribution, WCLP – Working Centre Linux Project, way back in 2001. By 2006 the project had switched to Ubuntu Linux. Ubuntu Linux was a rising star back in 2006, it made installing “difficult to install” proprietary drivers easy (compared to Debian). And because Ubuntu was based on Debian, people with Debian experience could easily adapt to Ubuntu.",
    "tags": [
      "Linux",
      "Ubuntu",
      "Desktop",
      "Software",
      "GNOME"
    ],
    "title": "Ubuntu 22.04 Jammy Jellyfish",
    "uri": "/posts/ubuntu_2204_jammy_jellyfish/index.html"
  },
  {
    "breadcrumb": "Chaslinux's Blog \u003e  Posts",
    "content": "",
    "description": "archives",
    "tags": [],
    "title": "Archives",
    "uri": "/archives/index.html"
  }
]
